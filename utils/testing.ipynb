{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread(\"../data/images/road818.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, title:str=\"Image\"):\n",
    "    cv.imshow(title, img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyWindow(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(bgr_image):\n",
    "    ycrcb_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    y, cr, cb = cv.split(ycrcb_image)\n",
    "    y_equalized = cv.equalizeHist(y)\n",
    "    equalized_image = cv.merge([y_equalized, cr, cb])\n",
    "    return cv.cvtColor(equalized_image, cv.COLOR_YCrCb2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_brightness_contrast(bgr_image, clip_hist_percent = 0.01, use_scale_abs = True, return_verbose = False):\n",
    "    gray_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Grayscale histogram of the image\n",
    "    hist = cv.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "    hist_size = len(hist)\n",
    "\n",
    "    # Cumulative distribution of the histogram\n",
    "    acc = []\n",
    "    acc.append( float(hist[0]) )\n",
    "    for i in range(1, hist_size):\n",
    "        acc.append( acc[i - 1] + float(hist[i]) )\n",
    "    \n",
    "    # Locate points to clip\n",
    "    maximum = acc[-1]\n",
    "    clip_hist = clip_hist_percent * maximum / 2.0\n",
    "\n",
    "    # Left cut\n",
    "    minimum_gray = 0\n",
    "    while acc[minimum_gray] < clip_hist:\n",
    "        minimum_gray += 1\n",
    "\n",
    "    # Right cut\n",
    "    maximum_gray = hist_size - 1\n",
    "    while acc[maximum_gray] >= (maximum - clip_hist):\n",
    "        maximum_gray -= 1\n",
    "\n",
    "    # Calculate alpha and beta values for the scaling\n",
    "    alpha = 255 / (maximum_gray - minimum_gray)\n",
    "    beta = - minimum_gray * alpha\n",
    "\n",
    "    if use_scale_abs:\n",
    "        processed_image = cv.convertScaleAbs(bgr_image, alpha=alpha, beta=beta)\n",
    "    else:\n",
    "        processed_image = bgr_image * alpha + beta\n",
    "        processed_image[processed_image < 0] = 0\n",
    "        processed_image[processed_image > 255] = 255\n",
    "\n",
    "    if return_verbose:\n",
    "        processed_hist = cv.calcHist([gray_image], [0], None, [256], [minimum_gray, maximum_gray])\n",
    "\n",
    "        return processed_image, alpha, beta, hist, processed_hist\n",
    "    \n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaplacianOfGaussian(bgr_image):\n",
    "    log_image = cv.GaussianBlur(bgr_image, (3, 3), 0)\n",
    "    gray_image = cv.cvtColor(log_image, cv.COLOR_BGR2GRAY)\n",
    "    log_image = cv.Laplacian(log_image, cv.CV_8U, ksize=3, scale=1, delta=0)\n",
    "    return cv.convertScaleAbs(log_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(image)\n",
    "\n",
    "new_img = automatic_brightness_contrast(image, clip_hist_percent=0.1, use_scale_abs=True)\n",
    "\n",
    "#new_img = LaplacianOfGaussian(new_img)\n",
    "show_img(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_red_hsv(hsv_image, return_split = False):\n",
    "    # First zone of reds\n",
    "    lowerbound_1 = np.array([0, 40, 25])\n",
    "    upperbound_1 = np.array([10, 255, 255])\n",
    "\n",
    "    # Second zone of reds\n",
    "    lowerbound_2 = np.array([135, 40, 25])\n",
    "    upperbound_2 = np.array([179, 255, 255])\n",
    "\n",
    "    red_1 = cv.inRange(hsv_image, lowerbound_1, upperbound_1)\n",
    "    red_2 = cv.inRange(hsv_image, lowerbound_2, upperbound_2)\n",
    "\n",
    "    if return_split:\n",
    "        return red_1, red_2\n",
    "    \n",
    "    return cv.bitwise_or(red_1, red_2)\n",
    "\n",
    "def extract_blue_hsv(hsv_image):\n",
    "    lowerbound = np.array([100, 160, 40])\n",
    "    upperbound = np.array([120, 255, 255])\n",
    "\n",
    "    return cv.inRange(hsv_image, lowerbound, upperbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(bgr_image, threshold_percent = 0.75, return_thresh = False):\n",
    "    gray_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    threshold = int(threshold_percent * 255)\n",
    "\n",
    "    thresh, thresh_image = cv.threshold(gray_image, threshold, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "    if return_thresh:\n",
    "        return thresh_image, thresh\n",
    "    return thresh_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractObjects(bgr_image, contours):\n",
    "    out_image = np.zeros_like(bgr_image)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv.boundingRect(contour)\n",
    "        out_image[y:y+h, x:x+w] = bgr_image[y:y+h, x:x+w]\n",
    "    \n",
    "    return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(red_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = extractObjects(image, contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_image = automatic_brightness_contrast(objects, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_mask = extract_red_hsv(objects)\n",
    "\n",
    "white_mask = cv.inRange(cv.cvtColor(objects, cv.COLOR_BGR2HSV), np.array([0, 0, 130]), np.array([255, 40, 255]))\n",
    "\n",
    "mask = cv.bitwise_or(red_mask, white_mask)\n",
    "\n",
    "cropped_objects = cv.bitwise_and(objects, objects, mask=mask)\n",
    "show_img(objects)\n",
    "show_img(cropped_objects)\n",
    "\n",
    "bin_image = binarize(cropped_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(bin_image)\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "morph_img = cv.morphologyEx(bin_image, cv.MORPH_DILATE, kernel)\n",
    "show_img(morph_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARMING FILTER\n",
    "# https://towardsdatascience.com/python-opencv-building-instagram-like-image-filters-5c482c1c5079\n",
    "\n",
    "def _create_LUT_8UC1(x, y):\n",
    "  spl = UnivariateSpline(x, y)\n",
    "  return spl(range(256))\n",
    "\n",
    "# TODO better lut values for reds\n",
    "incr_ch_lut = _create_LUT_8UC1([0, 64, 128, 256],[0, 80, 160, 256])\n",
    "decr_ch_lut = _create_LUT_8UC1([0, 64, 128, 256],[0, 50,  100, 255])\n",
    "\n",
    "def render(img_rgb):\n",
    "    c_r, c_g, c_b = cv.split(img_rgb)\n",
    "    c_r = cv.LUT(c_r, incr_ch_lut).astype(np.uint8)\n",
    "    c_b = cv.LUT(c_b, decr_ch_lut).astype(np.uint8)\n",
    "  \n",
    "    return  cv.merge((c_r, c_g, c_b)) \n",
    "\n",
    "bla = cv.cvtColor(src_image, cv.COLOR_BGR2RGB)  \n",
    "display_bgr_image(render(bla))\n",
    "\n",
    "src_image = bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_illumination_channel(I, w):\n",
    "    M, N, _ = I.shape\n",
    "    w_2 = int(w/2)\n",
    "    padded = np.pad(I, ( (w_2, w_2), (w_2, w_2), (0, 0)), \"edge\")\n",
    "    dark_channel = np.zeros(shape=(M, N))\n",
    "    bright_channel = np.zeros(shape=(M, N))\n",
    "\n",
    "    for i, j in np.ndindex(dark_channel.shape):\n",
    "        dark_channel[i, j] = np.min(padded[i:i+w, j:j+w, :])\n",
    "        bright_channel[i, j] = np.max(padded[i:i+w, j:j+w, :])\n",
    "\n",
    "    return dark_channel, bright_channel\n",
    "\n",
    "def get_atmosphere(I, bright_channel, p=0.1):\n",
    "    M, N = bright_channel.shape\n",
    "    flatI = I.reshape(M*N, 3)\n",
    "    flatBright = bright_channel.ravel()\n",
    "\n",
    "    search_idx = (-flatBright).argsort()[:int(M*N*p)]\n",
    "    return np.mean(flatI.take(search_idx, axis=0), dtype=np.float64, axis=0)\n",
    "\n",
    "def get_initial_transmission(A, bright_channel):\n",
    "    A_c = np.max(A)\n",
    "    init_t = (bright_channel - A_c) / (1.0 - A_c)\n",
    "    return (init_t - np.min(init_t)) / (np.max(init_t) - np.min(init_t))\n",
    "\n",
    "def reduce_init_t(init_t):\n",
    "    init_t = np.uint8(init_t * 255)\n",
    "    xp = [0, 32, 255]\n",
    "    fp = [0, 32, 48]\n",
    "    x = np.arange(256)\n",
    "    table = np.interp(x, xp, fp).astype(np.uint8)\n",
    "    init_t = cv.LUT(init_t, table)\n",
    "    return np.float64(init_t) / 255\n",
    "\n",
    "def corrected_transmission(I, A, dark_channel, bright_channel, init_t, alpha, omega, w):\n",
    "    im = np.empty(I.shape, I.dtype)\n",
    "    for ind in range(0, 3):\n",
    "        im[:, :, ind] = I[:, :, ind] / A[ind]\n",
    "    \n",
    "    dark_c, _ = get_illumination_channel(im, w)\n",
    "    dark_t = 1 - omega * dark_c\n",
    "    corrected_t = init_t\n",
    "    diff_channel = bright_channel - dark_channel\n",
    "    for i in range(diff_channel.shape[0]):\n",
    "        for j in range(diff_channel.shape[1]):\n",
    "            if diff_channel[i, j] < alpha:\n",
    "                corrected_t[i, j] = dark_t[i, j] * init_t[i, j]\n",
    "\n",
    "    return np.abs(corrected_t)\n",
    "\n",
    "def boxfilter(I, r):\n",
    "    \"\"\"Fast box filter implementation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    I:  a single channel/gray image data normalized to [0.0, 1.0]\n",
    "    r:  window radius\n",
    "    Return\n",
    "    -----------\n",
    "    The filtered image data.\n",
    "    \"\"\"\n",
    "    M, N = I.shape\n",
    "    dest = np.zeros((M, N))\n",
    "    \n",
    "    sumY = np.cumsum(I, axis=0)\n",
    "    # difference over Y axis\n",
    "    dest[:r + 1] = sumY[r:2*r + 1] # top r+1 lines\n",
    "    dest[r + 1:M - r] = sumY[2*r + 1:] - sumY[:M - 2*r - 1]\n",
    "    dest[-r:] = np.tile(sumY[-1], (r, 1)) - sumY[M - 2*r - 1:M - r - 1] # bottom r lines\n",
    "\n",
    "    sumX = np.cumsum(dest, axis=1)\n",
    "    # difference over X axis\n",
    "    dest[:, :r + 1] = sumX[:, r:2*r + 1] # left r+1 columns\n",
    "    dest[:, r + 1:N - r] = sumX[:, 2*r + 1:] - sumX[:, :N - 2*r - 1]\n",
    "    dest[:, -r:] = np.tile(sumX[:, -1][:, None], (1, r)) - sumX[:, N - 2*r - 1:N - r - 1] # right r columns\n",
    "\n",
    "    return dest\n",
    "\n",
    "\n",
    "def guided_filter(I, p, r=15, eps=1e-3):\n",
    "    \"\"\"Refine a filter under the guidance of another (RGB) image.\n",
    "    Parameters\n",
    "    -----------\n",
    "    I:   an M * N * 3 RGB image for guidance.\n",
    "    p:   the M * N filter to be guided. transmission is used for this case.\n",
    "    r:   the radius of the guidance\n",
    "    eps: epsilon for the guided filter\n",
    "    Return\n",
    "    -----------\n",
    "    The guided filter.\n",
    "    \"\"\"\n",
    "    from itertools import combinations_with_replacement\n",
    "    R, G, B = 0, 1, 2\n",
    "\n",
    "    M, N = p.shape\n",
    "    base = boxfilter(np.ones((M, N)), r) # this is needed for regularization\n",
    "    \n",
    "    # each channel of I filtered with the mean filter. this is myu.\n",
    "    means = [boxfilter(I[:, :, i], r) / base for i in range(3)]\n",
    "    \n",
    "    # p filtered with the mean filter\n",
    "    mean_p = boxfilter(p, r) / base\n",
    "\n",
    "    # filter I with p then filter it with the mean filter\n",
    "    means_IP = [boxfilter(I[:, :, i]*p, r) / base for i in range(3)]\n",
    "\n",
    "    # covariance of (I, p) in each local patch\n",
    "    covIP = [means_IP[i] - means[i]*mean_p for i in range(3)]\n",
    "\n",
    "    # variance of I in each local patch: the matrix Sigma in ECCV10 eq.14\n",
    "    var = defaultdict(dict)\n",
    "    for i, j in combinations_with_replacement(range(3), 2):\n",
    "        var[i][j] = boxfilter(I[:, :, i]*I[:, :, j], r) / base - means[i]*means[j]\n",
    "\n",
    "    a = np.zeros((M, N, 3))\n",
    "    for y, x in np.ndindex(M, N):\n",
    "        #         rr, rg, rb\n",
    "        # Sigma = rg, gg, gb\n",
    "        #         rb, gb, bb\n",
    "        Sigma = np.array([[var[R][R][y, x], var[R][G][y, x], var[R][B][y, x]],\n",
    "                          [var[R][G][y, x], var[G][G][y, x], var[G][B][y, x]],\n",
    "                          [var[R][B][y, x], var[G][B][y, x], var[B][B][y, x]]])\n",
    "        cov = np.array([c[y, x] for c in covIP])\n",
    "        a[y, x] = np.dot(cov, np.linalg.inv(Sigma + eps*np.eye(3)))  # eq 14\n",
    "\n",
    "    # ECCV10 eq.15\n",
    "    b = mean_p - a[:, :, R]*means[R] - a[:, :, G]*means[G] - a[:, :, B]*means[B]\n",
    "\n",
    "    # ECCV10 eq.16\n",
    "    q = (boxfilter(a[:, :, R], r)*I[:, :, R] + boxfilter(a[:, :, G], r)*I[:, :, G] + boxfilter(a[:, :, B], r)*I[:, :, B] + boxfilter(b, r)) / base\n",
    "\n",
    "    return q\n",
    "\n",
    "def get_final_image(I, A, refined_t, Tmin):\n",
    "    refined_t_broadcasted = np.broadcast_to(refined_t[:, :, None], (refined_t.shape[0], refined_t.shape[1], 3))\n",
    "    J = (I - A) / (np.where(refined_t_broadcasted < Tmin, Tmin, refined_t_broadcasted)) + A\n",
    "    return (J - np.min(J)) / (np.max(J) - np.min(J))\n",
    "\n",
    "def dehaze(image, Tmin = 0.1, w = 15, alpha = 0.4, omega = 0.75, p=0.1, eps=1e-3):\n",
    "    I = np.float64(image)\n",
    "    I = I[:, :, :3] / 255\n",
    "    M, N, _ = I.shape\n",
    "    Idark, Ibright = get_illumination_channel(I, w)\n",
    "    A = get_atmosphere(I, Ibright, p)\n",
    "\n",
    "    init_t = get_initial_transmission(A, Ibright)\n",
    "\n",
    "    init_t = reduce_init_t(init_t)\n",
    "\n",
    "    corrected_t = corrected_transmission(I, A, Idark, Ibright, init_t, alpha, omega, w)\n",
    "    normI = (I - I.min()) / (I.max() - I.min())\n",
    "\n",
    "    refined_t = guided_filter(normI, corrected_t, w, eps)\n",
    "    J_refined = get_final_image(I, A, refined_t, Tmin)\n",
    "\n",
    "    enhanced = np.uint8(J_refined * 255)\n",
    "    f_enhanced = cv.detailEnhance(enhanced, sigma_s=10, sigma_r=0.15)\n",
    "    f_enhanced = cv.edgePreservingFilter(f_enhanced, flags=cv.RECURS_FILTER, sigma_s=64, sigma_r=0.2)\n",
    "    return f_enhanced"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54c6638086fab4cdd44262421cfa14d1d96be689a356dd3ef0d28ae6e964d53f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
