{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.exposure import is_low_contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constant definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/images\"\n",
    "ANNOT_DIR = \"./data/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(value, minimum, maximum):\n",
    "    return min(maximum, max(minimum, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_bgr_image(bgr_image, show=True):\n",
    "    rgb_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(rgb_image)\n",
    "    ax.axis(False)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "def display_gray_image(gray_image, show=True):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(gray_image, cmap=\"gray\")\n",
    "    ax.axis(False)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_gray_transform(bgr_image, weights=[0.114, 0.587, 0.299]):\n",
    "    m = np.array(weights).reshape((1,3))\n",
    "    return cv.transform(bgr_image, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image = 873\n",
    "src_image = cv.imread(f\"{DATA_DIR}/road{selected_image}.png\")\n",
    "\n",
    "fig, ax = display_bgr_image(src_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "In this phase, the image will be treated in an attempt to reduce possible noise from environment and/or weather, this will be achieved by applying **CLAHE equalization** on the image, followed by an **automatic brightness and contrast correction** and finishing with the initial step of **meanShift**, this is the filtering stage of the **meanshift** segmentation that flattens color gradients and fine-grain textures of the image (see `pyrMeanShiftFiltering`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAHE Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_clahe_equalization(bgr_image, clipLimit = 2.0, tileGridSize = (8, 8)):\n",
    "    hsv_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    h, s, v = cv.split(hsv_image)\n",
    "\n",
    "    clahe = cv.createCLAHE(\n",
    "        clipLimit=clipLimit,\n",
    "        tileGridSize=tileGridSize\n",
    "    )\n",
    "\n",
    "    s_equalized = clahe.apply(s)\n",
    "    v_equalized = clahe.apply(v)\n",
    "\n",
    "    equalized_image = cv.merge([h, s_equalized, v_equalized])\n",
    "    return cv.cvtColor(equalized_image, cv.COLOR_HSV2BGR)\n",
    "\n",
    "clahe_image = hsv_clahe_equalization(src_image, clipLimit=2.0, tileGridSize=(8, 8))\n",
    "fig, ax = display_bgr_image(clahe_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Brightness and Contrast Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_brightness_contrast(bgr_image, clip_hist_percent = 0.01, use_scale_abs = True, return_verbose = False):\n",
    "    gray_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Grayscale histogram of the image\n",
    "    hist = cv.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "    hist_size = len(hist)\n",
    "\n",
    "    # Cumulative distribution of the histogram\n",
    "    acc = []\n",
    "    acc.append( float(hist[0]) )\n",
    "    for i in range(1, hist_size):\n",
    "        acc.append( acc[i - 1] + float(hist[i]) )\n",
    "    \n",
    "    # Locate points to clip\n",
    "    maximum = acc[-1]\n",
    "    clip_hist = clip_hist_percent * maximum / 2.0\n",
    "\n",
    "    # Left cut\n",
    "    minimum_gray = 0\n",
    "    while acc[minimum_gray] < clip_hist:\n",
    "        minimum_gray += 1\n",
    "\n",
    "    # Right cut\n",
    "    maximum_gray = hist_size - 1\n",
    "    while acc[maximum_gray] >= (maximum - clip_hist):\n",
    "        maximum_gray -= 1\n",
    "\n",
    "    # Calculate alpha and beta values for the scaling\n",
    "    alpha = 255 / (maximum_gray - minimum_gray)\n",
    "    beta = - minimum_gray * alpha\n",
    "\n",
    "    if use_scale_abs:\n",
    "        processed_image = cv.convertScaleAbs(bgr_image, alpha=alpha, beta=beta)\n",
    "    else:\n",
    "        processed_image = bgr_image * alpha + beta\n",
    "        processed_image[processed_image < 0] = 0\n",
    "        processed_image[processed_image > 255] = 255\n",
    "\n",
    "    if return_verbose:\n",
    "        processed_hist = cv.calcHist([gray_image], [0], None, [256], [minimum_gray, maximum_gray])\n",
    "\n",
    "        return processed_image, alpha, beta, hist, processed_hist\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "contrast_image = automatic_brightness_contrast(clahe_image, clip_hist_percent=0.01, use_scale_abs=True)\n",
    "fig, ax = display_bgr_image(contrast_image)\n",
    "plt.clf();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Shift Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image = cv.pyrMeanShiftFiltering(contrast_image, 10, 25, 100)\n",
    "fig, ax = display_bgr_image(processed_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase, the processed image will be segmented by color. It was decided to segment the reds and blues separately. Afterwards, the segmented image is binarized by application of thresholding techniques, in this case, it was decided to use Otsu technique for thresholding. Further more, it is done a small post-processing to remove small components of the image that aren't likely to be traffic signs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_reds(bgr_image):\n",
    "    smooth_image = cv.edgePreservingFilter(bgr_image, flags=cv.NORMCONV_FILTER, sigma_s=10, sigma_r=0.2)\n",
    "    hsv_image = cv.cvtColor(smooth_image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Red zones\n",
    "    lowerbound_1 = np.array([0, 40, 40])\n",
    "    upperbound_1 = np.array([15, 255, 255])\n",
    "\n",
    "    lowerbound_2 = np.array([135, 40, 40])\n",
    "    upperbound_2 = np.array([180, 255, 255])\n",
    "\n",
    "    red_1 = cv.inRange(hsv_image, lowerbound_1, upperbound_1)\n",
    "    red_2 = cv.inRange(hsv_image, lowerbound_2, upperbound_2)\n",
    "    mask = cv.bitwise_or(red_1, red_2)\n",
    "\n",
    "\n",
    "    segmented_image = cv.bitwise_and(smooth_image, smooth_image, mask=mask)\n",
    "    BIN_THRESHOLD = 0.75\n",
    "\n",
    "    gray_image = weighted_gray_transform(segmented_image, [0, 0, 1])\n",
    "\n",
    "    threshold = int(255 * BIN_THRESHOLD)\n",
    "    ret_thresh, gray_image = cv.threshold(gray_image, threshold, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "red_segmented_image = segment_reds(src_image)\n",
    "fig, ax = display_gray_image(red_segmented_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blue Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_blues(bgr_image):\n",
    "    smooth_image = cv.edgePreservingFilter(bgr_image, flags=cv.NORMCONV_FILTER, sigma_s=50, sigma_r=0.5)\n",
    "    hsv_image = cv.cvtColor(smooth_image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Blue zones\n",
    "    lowerbound = np.array([100, 40, 70])\n",
    "    upperbound = np.array([140, 255, 255])\n",
    "\n",
    "    mask = cv.inRange(hsv_image, lowerbound, upperbound)\n",
    "    \n",
    "    segmented_image = cv.bitwise_and(smooth_image, smooth_image, mask=mask)\n",
    "    BIN_THRESHOLD = 0.25\n",
    "\n",
    "    # gray_image = cv.cvtColor(segmented_image, cv.COLOR_BGR2GRAY)\n",
    "    gray_image = weighted_gray_transform(segmented_image, [1, 0, 0])\n",
    "\n",
    "    threshold = int(255 * BIN_THRESHOLD)\n",
    "    ret_thresh, gray_image = cv.threshold(gray_image, threshold, 255, cv.THRESH_BINARY)\n",
    "    # black_img = np.zeros(shape=bgr_image.shape[0:2], dtype=np.uint8)\n",
    "    # white_img = np.ones(shape=bgr_image.shape[0:2], dtype=np.uint8)*255\n",
    "    \n",
    "    # gray_image = cv.bitwise_or(black_img, white_img, mask=mask)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "blue_segmented_image = segment_blues(processed_image)\n",
    "fig, ax = display_gray_image(blue_segmented_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-segmentation Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: rethink the `removeSmallComponents`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoI Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase, it will be extracted the regions of interest (RoI) of the segmented images, those will be considered the potential traffic signs for the next phase. To do this extraction, it will be applied an edge detector followed by extracting the contours and then the bounding rectangle of that contour as the RoI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(gray_image):\n",
    "    # Apply morphological operation to soften possible artefacts\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, ksize=(3, 3))\n",
    "    morph_image = cv.morphologyEx(gray_image, cv.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    return cv.Canny(morph_image, threshold1=200, threshold2=240, apertureSize=5)\n",
    "\n",
    "    \n",
    "\n",
    "red_edges = edge_detection(red_segmented_image)\n",
    "print(\"Edges of Red Segmented Image\")\n",
    "fig, ax = display_gray_image(red_edges)\n",
    "plt.clf();\n",
    "\n",
    "blue_edges = edge_detection(blue_segmented_image)\n",
    "print(\"Edges of Blue Segmented Image\")\n",
    "fig, ax = display_gray_image(blue_edges)\n",
    "plt.clf();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract RoI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regions of interest will be bounding rectangles of the contours detected in the image processed by Canny edge detector. To eliminate redundant RoI and false positives, RoI that are contained completely inside another will be merged, and RoI which don't meet certain criteria will also be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeROI(rois):\n",
    "    # Sort RoI by X-coordinate and width to merge RoI\n",
    "    sorted_rois = sorted(rois, key=lambda roi: (roi[0][0], -roi[0][2], roi[0][1], -roi[0][3]))\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= len(sorted_rois):\n",
    "            break\n",
    "\n",
    "        pivot = sorted_rois[i]\n",
    "        pivot_x0, pivot_y0, pivot_x1, pivot_y1 = pivot[0][0], pivot[0][1], pivot[0][0] + pivot[0][2], pivot[0][1] + pivot[0][3]\n",
    "        j = i + 1\n",
    "        while True:\n",
    "            if j >= len(sorted_rois):\n",
    "                break\n",
    "\n",
    "            other = sorted_rois[j]\n",
    "            other_x0, other_y0, other_x1, other_y1 = other[0][0], other[0][1], other[0][0] + other[0][2], other[0][1] + other[0][3]\n",
    "        \n",
    "            # Beginning of other RoI is already past the ending of the pivot RoI\n",
    "            if other_x0 > pivot_x1:\n",
    "                break\n",
    "\n",
    "            # Check if it's inside, and delete if so, otherwise advance\n",
    "            if other_y0 > pivot_y0 and other_y1 < pivot_y1 and other_x1 < pivot_x1:\n",
    "                sorted_rois.pop(j)\n",
    "            else:\n",
    "                j += 1\n",
    "        \n",
    "        i += 1\n",
    "    return sorted_rois\n",
    "\n",
    "\n",
    "def extractROI(edge_image, red_image, blue_image, roi_type):\n",
    "    kernel = cv.getStructuringElement(shape=cv.MORPH_ELLIPSE, ksize=(3, 3))\n",
    "    morph_image = cv.morphologyEx(edge_image, cv.MORPH_DILATE, kernel, iterations=1)\n",
    "\n",
    "    contours, hierarchy = cv.findContours(morph_image, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Apply convex hulls to close off shapes\n",
    "    contours = [cv.convexHull(contour) for contour in contours]\n",
    "\n",
    "    # Approximate contour\n",
    "    contours = [cv.approxPolyDP(contour, 0.01 * cv.arcLength(contour, True), True) for contour in contours]\n",
    "\n",
    "    rois = [(cv.boundingRect(contour), contour) for contour in contours]\n",
    "\n",
    "    rois = mergeROI(rois)\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= len(rois):\n",
    "            break\n",
    "\n",
    "        (x, y, w, h), contours = rois[i]\n",
    "        roi_size = w * h\n",
    "\n",
    "        SIZE_THRESHOLD = 15 * 15\n",
    "        if roi_size < SIZE_THRESHOLD:\n",
    "            rois.pop(i)\n",
    "            continue\n",
    "\n",
    "        ASPECT_RATIO_MIN = 0.45\n",
    "        ASPECT_RATIO_MAX = 1.55\n",
    "        aspect_ratio = float(w) / h\n",
    "        if aspect_ratio < ASPECT_RATIO_MIN or aspect_ratio > ASPECT_RATIO_MAX: \n",
    "            rois.pop(i)\n",
    "            continue\n",
    "\n",
    "        blue_pixels = 0\n",
    "        red_pixels = 0\n",
    "        for xi in range(x, x+w):\n",
    "            for yi in range(y, y+h):\n",
    "                if cv.pointPolygonTest(contours, (xi, yi), measureDist=False) >= 0:\n",
    "                    if red_image[yi, xi] > 127:\n",
    "                        red_pixels += 1\n",
    "                    if blue_image[yi, xi] > 127:\n",
    "                        blue_pixels += 1\n",
    "\n",
    "        blue_ratio = blue_pixels / roi_size\n",
    "        red_ratio = red_pixels / roi_size\n",
    "        red_blue_ratio = red_pixels / (blue_pixels + 1e-4)\n",
    "\n",
    "        if roi_type == \"red\":\n",
    "            if red_ratio < 0.10:\n",
    "                rois.pop(i)\n",
    "                continue\n",
    "        elif roi_type == \"blue\":\n",
    "            if blue_ratio < 0.40:\n",
    "                rois.pop(i)\n",
    "                continue\n",
    "        \n",
    "        rois[i] = ((x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio)\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    return rois\n",
    "\n",
    "red_roi = extractROI(red_edges, red_image=red_segmented_image, blue_image=blue_segmented_image, roi_type=\"red\")\n",
    "\n",
    "blue_roi = extractROI(blue_edges, red_image=red_segmented_image, blue_image=blue_segmented_image, roi_type=\"blue\")\n",
    "\n",
    "roi_red_image = np.zeros(shape=(red_edges.shape + (3,)), dtype=np.uint8)\n",
    "print(\"Red Regions of Interest\")\n",
    "for roi in red_roi:\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    cv.rectangle(roi_red_image, (int(x), int(y)), (int(x+w), int(y+h)), (197, 183, 255), 1)\n",
    "    cv.drawContours(roi_red_image, [contours], 0, color=(255, 255, 255))\n",
    "    region = np.zeros_like(red_edges[y:y+h, x:x+w])\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "display_bgr_image(roi_red_image)\n",
    "plt.clf();\n",
    "\n",
    "print(\"Blue Regions of Interest\")\n",
    "roi_blue_image = np.zeros(shape=(red_edges.shape + (3,)), dtype=np.uint8)\n",
    "for roi in blue_roi:\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    cv.rectangle(roi_blue_image, (int(x), int(y)), (int(x+w), int(y+h)), (197, 183, 255), 1)\n",
    "    cv.drawContours(roi_blue_image, [contours], 0, color=(255, 255, 255))\n",
    "    region = np.zeros_like(blue_edges[y:y+h, x:x+w])\n",
    "    # for x0 in range(x, x+w):\n",
    "    #     for y0 in range(y, y+h):\n",
    "    #         if cv.pointPolygonTest(contours, (x0, y0), measureDist=False) >= 0:\n",
    "    #             region[y0-y, x0-x] = 255\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "display_bgr_image(roi_blue_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_detection(roi, gray_image):\n",
    "    (x, y, w, h), contours, _, _, _ = roi\n",
    "    region = np.zeros(shape=(h, w), dtype=np.uint8)\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "    region_32f = np.float32(region)\n",
    "\n",
    "    corners = cv.cornerHarris(region_32f, 6, 3, 0.04)\n",
    "    corners = cv.dilate(corners, None)\n",
    "\n",
    "    norm_corners = np.empty(corners.shape, dtype=np.float32)\n",
    "    cv.normalize(corners, norm_corners, 255.0, 0.0, cv.NORM_INF)\n",
    "    norm_corners = cv.convertScaleAbs(norm_corners)\n",
    "\n",
    "    CORNER_THRESHOLD = 60\n",
    "\n",
    "    w_20, h_20 = int(0.20 * w), int(0.20 * h)\n",
    "    tl = 0.25 * (norm_corners[0:h_20, 0:w_20].max() > CORNER_THRESHOLD)\n",
    "    tc = 0.25 * (norm_corners[0:h_20, 2*w_20:3*w_20].max() > CORNER_THRESHOLD)\n",
    "    tr = 0.25 * (norm_corners[0:h_20, 4*w_20:5*w_20].max() > CORNER_THRESHOLD)\n",
    "\n",
    "    ml = 0.25 * (norm_corners[2*h_20:3*h_20, 0:w_20].max() > CORNER_THRESHOLD)\n",
    "    mr = 0.25 * (norm_corners[2*h_20:3*h_20, 4*w_20:5*w_20].max() > CORNER_THRESHOLD)\n",
    "\n",
    "    bl = 0.25 * (norm_corners[4*h_20:5*h_20, 0:w_20].max() > CORNER_THRESHOLD)\n",
    "    bc = 0.25 * (norm_corners[4*h_20:5*h_20, 2*w_20:3*w_20].max() > CORNER_THRESHOLD)\n",
    "    br = 0.25 * (norm_corners[4*h_20:5*h_20, 4*w_20:5*w_20].max() > CORNER_THRESHOLD)\n",
    "\n",
    "    sqp = clamp(tl + tr + br + bl - ml - mr - tc - bc, 0.0, 1.0)\n",
    "    tup = clamp(1/0.75 * (bl + br + tc) - 1.1 * (tl + tr) - 0.9 * (ml + mr), 0.0, 1.0)\n",
    "    tdp = clamp(1/0.75 * (tl + tr + bc) - 1.1 * (bl + br) - 0.9 * (ml + mr), 0.0, 1.0)\n",
    "    circle = clamp((2 * (tc + bc + ml + mr) + 0.5 * (tl + tr + bl + br)) / 2.5, 0.0, 1.0)\n",
    "\n",
    "    display_gray_image(region)\n",
    "    plt.clf();\n",
    "    display_gray_image(norm_corners)\n",
    "    plt.clf();\n",
    "    return sqp, max(tup, tdp), circle\n",
    "\n",
    "print(\"Corner detection on reds\")\n",
    "for i in range(len(red_roi)):\n",
    "    roi = red_roi[i]\n",
    "    (brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    sqp, trg, circle = corner_detection(roi, red_edges)\n",
    "    red_roi[i] = ((brect_x, brect_y, brect_w, brect_h), contour,  red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle)\n",
    "\n",
    "print(\"Corner detection on blues\")\n",
    "for i in range(len(blue_roi)):\n",
    "    roi = blue_roi[i]\n",
    "    (brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    sqp, trg, circle = corner_detection(roi, blue_edges)\n",
    "    blue_roi[i] = ((brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometrical Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical ratios\n",
    "circularity_ratios = {\n",
    "    \"circle\": 1,\n",
    "    \"quadrilateral\": 0.70,\n",
    "    \"octagon\": 0.92,\n",
    "    \"triangle\": 0.41,\n",
    "    # \"diamond\": 0.64,\n",
    "}\n",
    "\n",
    "extent_ratios = {\n",
    "    \"circle\": 0.785,\n",
    "    \"quadrilateral\": 1,\n",
    "    \"octagon\": 0.829,\n",
    "    \"triangle\": 0.498,\n",
    "    # \"diamond\": 0.5,\n",
    "}\n",
    "\n",
    "minextent_ratios = {\n",
    "    \"circle\": 0.785,\n",
    "    \"quadrilateral\": 1,\n",
    "    \"octagon\": 0.829,\n",
    "    \"triangle\": 0.498,\n",
    "    # \"diamond\": 1\n",
    "}\n",
    "\n",
    "red_ratios = {\n",
    "    \"circle\": 0.30,\n",
    "    \"quadrilateral\": 0.0,\n",
    "    \"octagon\": 0.65,\n",
    "    \"triangle\": 0.20,\n",
    "}\n",
    "\n",
    "blue_ratios = {\n",
    "    \"circle\": 0.60,\n",
    "    \"quadrilateral\": 0.60,\n",
    "    \"octagon\": 0.0,\n",
    "    \"triangle\": 0.0,\n",
    "}\n",
    "\n",
    "output_classes = defaultdict(lambda: \"unknown\", {\n",
    "    (\"circle\", \"red\"): \"prohibitory\",\n",
    "    (\"triangle\", \"red\"): \"priority\",\n",
    "    (\"octagon\", \"red\"): \"stop\",\n",
    "\n",
    "    (\"quadrilateral\", \"blue\"): \"information\",\n",
    "    (\"circle\", \"blue\"): \"mandatory\",\n",
    "})\n",
    "\n",
    "def detect_shape(roi, roi_type, return_probabilities = False):\n",
    "    (brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle = roi\n",
    "\n",
    "    contourArea = cv.contourArea(contour)\n",
    "    contourPerimeter = cv.arcLength(contour, True)\n",
    "    # Bounding Rectangle Area - used to calculate extent of contour\n",
    "    brect_area = brect_w * brect_h\n",
    "    extent = contourArea / brect_area\n",
    "\n",
    "    # Minimum Bounding Rectangle - takes into account orientation and fits the bounding rectangle thighly\n",
    "    (min_brect_x0, min_brect_y0), (min_brect_x1, min_brect_y1), min_brect_angle = cv.minAreaRect(contour)\n",
    "    min_brect_area = abs(min_brect_x0 - min_brect_x1) * abs(min_brect_y0 - min_brect_y1)\n",
    "\n",
    "    min_extent = contourArea / min_brect_area\n",
    "\n",
    "    # Circularity - measures how compact the contour is\n",
    "    circularity = (4 * np.pi * contourArea) / (contourPerimeter * contourPerimeter + 1e-4)\n",
    "\n",
    "    # Minimum Enclosing Circle - similar to circularity\n",
    "    (min_circle_x, min_circle_y), circle_radius = cv.minEnclosingCircle(contour)\n",
    "    min_circle_area = np.pi * circle_radius * circle_radius\n",
    "\n",
    "    circle_extent = contourArea / min_circle_area\n",
    "\n",
    "    metrics = [\"circularity\", \"circle_extent\", \"extent\", \"min_extent\"]\n",
    "    ratios = [circularity, circle_extent, extent, min_extent]\n",
    "    ratio_tables = [circularity_ratios, circularity_ratios, extent_ratios, minextent_ratios]\n",
    "    if roi_type == \"red\":\n",
    "        metrics.append(\"color_ratio\")\n",
    "        ratios.append(red_ratio)\n",
    "        ratio_tables.append(red_ratios)\n",
    "    elif roi_type == \"blue\":\n",
    "        metrics.append(\"color_ratio\")\n",
    "        ratios.append(blue_ratio)\n",
    "        ratio_tables.append(blue_ratios)\n",
    "    \n",
    "    metrics.append(\"corners\")\n",
    "    n_metrics = len(metrics)\n",
    "\n",
    "    classes = [\"circle\", \"quadrilateral\", \"octagon\", \"triangle\"] # Add diamond\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    probability_table = np.zeros(shape=(n_metrics + 1, n_classes + 1))\n",
    "    for i in range(n_metrics - 1):\n",
    "        ratio = ratios[i]\n",
    "        table = ratio_tables[i]\n",
    "        for j in range(n_classes):\n",
    "            shape_class = classes[j]\n",
    "            class_ratio = table[shape_class]\n",
    "            probability_table[i, j] = abs(ratio - class_ratio) ** 2 # / (class_ratio + 1e-6)\n",
    "        \n",
    "        probability_table[i, n_classes] = np.sum(probability_table[i, 0:n_classes])\n",
    "        probability_table[i, 0:n_classes] = (1 - (probability_table[i, 0:n_classes] / probability_table[i, n_classes])) / (n_classes - 1)\n",
    "        probability_table[i, n_classes] = np.sum(probability_table[i, 0:n_classes])\n",
    "\n",
    "    # Add corners row\n",
    "    probability_table[n_metrics - 1, :n_classes] = np.array([circle, sqp, circle, trg])\n",
    "    probability_table[n_metrics - 1, n_classes] = np.sum(probability_table[n_metrics - 1, 0:n_classes])\n",
    "    probability_table[n_metrics - 1, :n_classes] /= probability_table[n_metrics - 1, n_classes]\n",
    "\n",
    "    probability_table[-1, :n_classes] = np.mean(probability_table[:-1, :-1], axis=0)\n",
    "    probability_table[-1, n_classes] = np.sum(probability_table[-1, 0:n_classes])\n",
    "\n",
    "    chosen_shape = \"\"\n",
    "    max_probability = -1\n",
    "    for i, shape in enumerate(classes):\n",
    "        p = probability_table[-1, i] \n",
    "        if p > max_probability:\n",
    "            chosen_shape = shape\n",
    "            max_probability = p\n",
    "\n",
    "    CONFIDENCE = 0.1 # Confidence threshold, how much % is needed to obtain majority\n",
    "    THRESHOLD = (1 / n_classes) * (1 + CONFIDENCE)\n",
    "    if max_probability < THRESHOLD:\n",
    "        chosen_shape = \"other\"\n",
    "        max_probability = -1\n",
    "\n",
    "    if roi_type == \"red\":\n",
    "        if chosen_shape == \"quadrilateral\":\n",
    "            chosen_shape = \"other\"\n",
    "        elif chosen_shape == \"circle\" or chosen_shape == \"octagon\":\n",
    "            if red_ratio > 0.45:\n",
    "                chosen_shape = \"octagon\"\n",
    "            else:\n",
    "                chosen_shape = \"circle\"\n",
    "    elif roi_type == \"blue\":\n",
    "        if chosen_shape == \"triangle\" or chosen_shape == \"octagon\":\n",
    "            chosen_shape = \"other\"\n",
    "\n",
    "    if return_probabilities:\n",
    "        df = pd.DataFrame(data=probability_table[:, :-1], columns=classes, index=metrics + [\"AVG(P)\"])\n",
    "        return chosen_shape, max_probability, df, THRESHOLD\n",
    "\n",
    "    return chosen_shape\n",
    "\n",
    "output_image = src_image.copy()\n",
    "print(\"Shape detection for red RoI\")\n",
    "for roi in red_roi:\n",
    "    shape, prob, prob_table, threshold = detect_shape(roi, \"red\", return_probabilities=True)\n",
    "\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle = roi\n",
    "    region = np.zeros_like(red_edges[y:y+h, x:x+w])\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "\n",
    "    print(f\"Red Ratio: {red_ratio}\")\n",
    "    print(f\"Blue Ratio: {blue_ratio}\")\n",
    "    print(f\"Red Blue Ratio: {red_blue_ratio}\")\n",
    "    print(f\"Detected {shape} with probability of {prob}. Minimum threshold was {threshold}\")\n",
    "    print(prob_table)\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "    # Draw output\n",
    "    if shape != \"other\":\n",
    "        cv.drawContours(output_image, [contours], 0, color=(25, 255, 40), thickness=2)\n",
    "        output_class = output_classes[(shape, \"red\")]\n",
    "        cv.putText(output_image, output_class, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.6, (25, 255, 40), 2, cv.LINE_AA)\n",
    "\n",
    "print(\"Shape detection for blue RoI\")\n",
    "for roi in blue_roi:\n",
    "    shape, prob, prob_table, threshold = detect_shape(roi, \"blue\", return_probabilities=True)\n",
    "\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle = roi\n",
    "    region = np.zeros_like(blue_edges[y:y+h, x:x+w])\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "\n",
    "    print(f\"Red Ratio: {red_ratio}\")\n",
    "    print(f\"Blue Ratio: {blue_ratio}\")\n",
    "    print(f\"Red Blue Ratio: {red_blue_ratio}\")\n",
    "    print(f\"Detected {shape} with probability of {prob}. Minimum threshold was {threshold}\")\n",
    "    print(prob_table)\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "    # Draw output\n",
    "    if shape != \"other\":\n",
    "        cv.drawContours(output_image, [contours], 0, color=(25, 255, 40), thickness=2)\n",
    "        output_class = output_classes[(shape, \"blue\")]\n",
    "        cv.putText(output_image, output_class, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.6, (25, 255, 40), 2, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bgr_image(output_image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54c6638086fab4cdd44262421cfa14d1d96be689a356dd3ef0d28ae6e964d53f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
