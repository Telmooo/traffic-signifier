{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.exposure import is_low_contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Constant definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/images\"\n",
    "ANNOT_DIR = \"./data/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(value, minimum, maximum):\n",
    "    return min(maximum, max(minimum, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_bgr_image(bgr_image, show=True):\n",
    "    rgb_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(rgb_image)\n",
    "    ax.axis(False)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "def display_gray_image(gray_image, show=True):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(gray_image, cmap=\"gray\")\n",
    "    ax.axis(False)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_gray_transform(bgr_image, weights=[0.114, 0.587, 0.299]):\n",
    "    m = np.array(weights).reshape((1,3))\n",
    "    return cv.transform(bgr_image, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_illumination_channel(I, w):\n",
    "    M, N, _ = I.shape\n",
    "    w_2 = int(w/2)\n",
    "    padded = np.pad(I, ( (w_2, w_2), (w_2, w_2), (0, 0)), \"edge\")\n",
    "    dark_channel = np.zeros(shape=(M, N))\n",
    "    bright_channel = np.zeros(shape=(M, N))\n",
    "\n",
    "    for i, j in np.ndindex(dark_channel.shape):\n",
    "        dark_channel[i, j] = np.min(padded[i:i+w, j:j+w, :])\n",
    "        bright_channel[i, j] = np.max(padded[i:i+w, j:j+w, :])\n",
    "\n",
    "    return dark_channel, bright_channel\n",
    "\n",
    "def get_atmosphere(I, bright_channel, p=0.1):\n",
    "    M, N = bright_channel.shape\n",
    "    flatI = I.reshape(M*N, 3)\n",
    "    flatBright = bright_channel.ravel()\n",
    "\n",
    "    search_idx = (-flatBright).argsort()[:int(M*N*p)]\n",
    "    return np.mean(flatI.take(search_idx, axis=0), dtype=np.float64, axis=0)\n",
    "\n",
    "def get_initial_transmission(A, bright_channel):\n",
    "    A_c = np.max(A)\n",
    "    init_t = (bright_channel - A_c) / (1.0 - A_c)\n",
    "    return (init_t - np.min(init_t)) / (np.max(init_t) - np.min(init_t))\n",
    "\n",
    "def reduce_init_t(init_t):\n",
    "    init_t = np.uint8(init_t * 255)\n",
    "    xp = [0, 32, 255]\n",
    "    fp = [0, 32, 48]\n",
    "    x = np.arange(256)\n",
    "    table = np.interp(x, xp, fp).astype(np.uint8)\n",
    "    init_t = cv.LUT(init_t, table)\n",
    "    return np.float64(init_t) / 255\n",
    "\n",
    "def corrected_transmission(I, A, dark_channel, bright_channel, init_t, alpha, omega, w):\n",
    "    im = np.empty(I.shape, I.dtype)\n",
    "    for ind in range(0, 3):\n",
    "        im[:, :, ind] = I[:, :, ind] / A[ind]\n",
    "    \n",
    "    dark_c, _ = get_illumination_channel(im, w)\n",
    "    dark_t = 1 - omega * dark_c\n",
    "    corrected_t = init_t\n",
    "    diff_channel = bright_channel - dark_channel\n",
    "    for i in range(diff_channel.shape[0]):\n",
    "        for j in range(diff_channel.shape[1]):\n",
    "            if diff_channel[i, j] < alpha:\n",
    "                corrected_t[i, j] = dark_t[i, j] * init_t[i, j]\n",
    "\n",
    "    return np.abs(corrected_t)\n",
    "\n",
    "def boxfilter(I, r):\n",
    "    \"\"\"Fast box filter implementation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    I:  a single channel/gray image data normalized to [0.0, 1.0]\n",
    "    r:  window radius\n",
    "    Return\n",
    "    -----------\n",
    "    The filtered image data.\n",
    "    \"\"\"\n",
    "    M, N = I.shape\n",
    "    dest = np.zeros((M, N))\n",
    "    \n",
    "    sumY = np.cumsum(I, axis=0)\n",
    "    # difference over Y axis\n",
    "    dest[:r + 1] = sumY[r:2*r + 1] # top r+1 lines\n",
    "    dest[r + 1:M - r] = sumY[2*r + 1:] - sumY[:M - 2*r - 1]\n",
    "    dest[-r:] = np.tile(sumY[-1], (r, 1)) - sumY[M - 2*r - 1:M - r - 1] # bottom r lines\n",
    "\n",
    "    sumX = np.cumsum(dest, axis=1)\n",
    "    # difference over X axis\n",
    "    dest[:, :r + 1] = sumX[:, r:2*r + 1] # left r+1 columns\n",
    "    dest[:, r + 1:N - r] = sumX[:, 2*r + 1:] - sumX[:, :N - 2*r - 1]\n",
    "    dest[:, -r:] = np.tile(sumX[:, -1][:, None], (1, r)) - sumX[:, N - 2*r - 1:N - r - 1] # right r columns\n",
    "\n",
    "    return dest\n",
    "\n",
    "\n",
    "def guided_filter(I, p, r=15, eps=1e-3):\n",
    "    \"\"\"Refine a filter under the guidance of another (RGB) image.\n",
    "    Parameters\n",
    "    -----------\n",
    "    I:   an M * N * 3 RGB image for guidance.\n",
    "    p:   the M * N filter to be guided. transmission is used for this case.\n",
    "    r:   the radius of the guidance\n",
    "    eps: epsilon for the guided filter\n",
    "    Return\n",
    "    -----------\n",
    "    The guided filter.\n",
    "    \"\"\"\n",
    "    from itertools import combinations_with_replacement\n",
    "    R, G, B = 0, 1, 2\n",
    "\n",
    "    M, N = p.shape\n",
    "    base = boxfilter(np.ones((M, N)), r) # this is needed for regularization\n",
    "    \n",
    "    # each channel of I filtered with the mean filter. this is myu.\n",
    "    means = [boxfilter(I[:, :, i], r) / base for i in range(3)]\n",
    "    \n",
    "    # p filtered with the mean filter\n",
    "    mean_p = boxfilter(p, r) / base\n",
    "\n",
    "    # filter I with p then filter it with the mean filter\n",
    "    means_IP = [boxfilter(I[:, :, i]*p, r) / base for i in range(3)]\n",
    "\n",
    "    # covariance of (I, p) in each local patch\n",
    "    covIP = [means_IP[i] - means[i]*mean_p for i in range(3)]\n",
    "\n",
    "    # variance of I in each local patch: the matrix Sigma in ECCV10 eq.14\n",
    "    var = defaultdict(dict)\n",
    "    for i, j in combinations_with_replacement(range(3), 2):\n",
    "        var[i][j] = boxfilter(I[:, :, i]*I[:, :, j], r) / base - means[i]*means[j]\n",
    "\n",
    "    a = np.zeros((M, N, 3))\n",
    "    for y, x in np.ndindex(M, N):\n",
    "        #         rr, rg, rb\n",
    "        # Sigma = rg, gg, gb\n",
    "        #         rb, gb, bb\n",
    "        Sigma = np.array([[var[R][R][y, x], var[R][G][y, x], var[R][B][y, x]],\n",
    "                          [var[R][G][y, x], var[G][G][y, x], var[G][B][y, x]],\n",
    "                          [var[R][B][y, x], var[G][B][y, x], var[B][B][y, x]]])\n",
    "        cov = np.array([c[y, x] for c in covIP])\n",
    "        a[y, x] = np.dot(cov, np.linalg.inv(Sigma + eps*np.eye(3)))  # eq 14\n",
    "\n",
    "    # ECCV10 eq.15\n",
    "    b = mean_p - a[:, :, R]*means[R] - a[:, :, G]*means[G] - a[:, :, B]*means[B]\n",
    "\n",
    "    # ECCV10 eq.16\n",
    "    q = (boxfilter(a[:, :, R], r)*I[:, :, R] + boxfilter(a[:, :, G], r)*I[:, :, G] + boxfilter(a[:, :, B], r)*I[:, :, B] + boxfilter(b, r)) / base\n",
    "\n",
    "    return q\n",
    "\n",
    "def get_final_image(I, A, refined_t, Tmin):\n",
    "    refined_t_broadcasted = np.broadcast_to(refined_t[:, :, None], (refined_t.shape[0], refined_t.shape[1], 3))\n",
    "    J = (I - A) / (np.where(refined_t_broadcasted < Tmin, Tmin, refined_t_broadcasted)) + A\n",
    "    return (J - np.min(J)) / (np.max(J) - np.min(J))\n",
    "\n",
    "def dehaze(image, Tmin = 0.1, w = 15, alpha = 0.4, omega = 0.75, p=0.1, eps=1e-3):\n",
    "    I = np.float64(image)\n",
    "    I = I[:, :, :3] / 255\n",
    "    M, N, _ = I.shape\n",
    "    Idark, Ibright = get_illumination_channel(I, w)\n",
    "    A = get_atmosphere(I, Ibright, p)\n",
    "\n",
    "    init_t = get_initial_transmission(A, Ibright)\n",
    "\n",
    "    init_t = reduce_init_t(init_t)\n",
    "\n",
    "    corrected_t = corrected_transmission(I, A, Idark, Ibright, init_t, alpha, omega, w)\n",
    "    normI = (I - I.min()) / (I.max() - I.min())\n",
    "\n",
    "    refined_t = guided_filter(normI, corrected_t, w, eps)\n",
    "    J_refined = get_final_image(I, A, refined_t, Tmin)\n",
    "\n",
    "    enhanced = np.uint8(J_refined * 255)\n",
    "    f_enhanced = cv.detailEnhance(enhanced, sigma_s=10, sigma_r=0.15)\n",
    "    f_enhanced = cv.edgePreservingFilter(f_enhanced, flags=cv.RECURS_FILTER, sigma_s=64, sigma_r=0.2)\n",
    "    return f_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image = 545\n",
    "src_image = cv.imread(f\"{DATA_DIR}/road{selected_image}.png\")\n",
    "\n",
    "fig, ax = display_bgr_image(src_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Image Processing\n",
    "In this phase, the image will be treated in an attempt to reduce possible noise from environment and/or weather, this will be achieved by applying **CLAHE equalization** on the image, followed by an **automatic brightness and contrast correction** and finishing with the initial step of **meanShift**, this is the filtering stage of the **meanshift** segmentation that flattens color gradients and fine-grain textures of the image (see `pyrMeanShiftFiltering`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CLAHE Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_clahe_equalization(bgr_image, clipLimit = 2.0, tileGridSize = (8, 8)):\n",
    "    hsv_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    h, s, v = cv.split(hsv_image)\n",
    "\n",
    "    clahe = cv.createCLAHE(\n",
    "        clipLimit=clipLimit,\n",
    "        tileGridSize=tileGridSize\n",
    "    )\n",
    "\n",
    "    s_equalized = clahe.apply(s)\n",
    "    v_equalized = clahe.apply(v)\n",
    "\n",
    "    equalized_image = cv.merge([h, s_equalized, v_equalized])\n",
    "    return cv.cvtColor(equalized_image, cv.COLOR_HSV2BGR)\n",
    "\n",
    "clahe_image = hsv_clahe_equalization(src_image, clipLimit=2.0, tileGridSize=(8, 8))\n",
    "fig, ax = display_bgr_image(clahe_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Automatic Brightness and Contrast Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_brightness_contrast(bgr_image, clip_hist_percent = 0.01, use_scale_abs = True, return_verbose = False):\n",
    "    gray_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Grayscale histogram of the image\n",
    "    hist = cv.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "    hist_size = len(hist)\n",
    "\n",
    "    # Cumulative distribution of the histogram\n",
    "    acc = []\n",
    "    acc.append( float(hist[0]) )\n",
    "    for i in range(1, hist_size):\n",
    "        acc.append( acc[i - 1] + float(hist[i]) )\n",
    "    \n",
    "    # Locate points to clip\n",
    "    maximum = acc[-1]\n",
    "    clip_hist = clip_hist_percent * maximum / 2.0\n",
    "\n",
    "    # Left cut\n",
    "    minimum_gray = 0\n",
    "    while acc[minimum_gray] < clip_hist:\n",
    "        minimum_gray += 1\n",
    "\n",
    "    # Right cut\n",
    "    maximum_gray = hist_size - 1\n",
    "    while acc[maximum_gray] >= (maximum - clip_hist):\n",
    "        maximum_gray -= 1\n",
    "\n",
    "    # Calculate alpha and beta values for the scaling\n",
    "    alpha = 255 / (maximum_gray - minimum_gray + 1e-6)\n",
    "    beta = - minimum_gray * alpha\n",
    "\n",
    "    if use_scale_abs:\n",
    "        processed_image = cv.convertScaleAbs(bgr_image, alpha=alpha, beta=beta)\n",
    "    else:\n",
    "        processed_image = bgr_image * alpha + beta\n",
    "        processed_image[processed_image < 0] = 0\n",
    "        processed_image[processed_image > 255] = 255\n",
    "\n",
    "    if return_verbose:\n",
    "        processed_hist = cv.calcHist([gray_image], [0], None, [256], [minimum_gray, maximum_gray])\n",
    "\n",
    "        return processed_image, alpha, beta, hist, processed_hist\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "contrast_image = automatic_brightness_contrast(clahe_image, clip_hist_percent=0.01, use_scale_abs=True)\n",
    "fig, ax = display_bgr_image(contrast_image)\n",
    "plt.clf();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mean Shift Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image = cv.pyrMeanShiftFiltering(contrast_image, 10, 25, 100)\n",
    "fig, ax = display_bgr_image(processed_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Color Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this phase, the processed image will be segmented by color. It was decided to segment the reds and blues separately. Afterwards, the segmented image is binarized by application of thresholding techniques, in this case, it was decided to use Otsu technique for thresholding. Further more, it is done a small post-processing to remove small components of the image that aren't likely to be traffic signs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Red Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_reds(bgr_image):\n",
    "    smooth_image = cv.edgePreservingFilter(bgr_image, flags=cv.NORMCONV_FILTER, sigma_s=10, sigma_r=0.2)\n",
    "    hsv_image = cv.cvtColor(smooth_image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Red zones\n",
    "    lowerbound_1 = np.array([0, 40, 40])\n",
    "    upperbound_1 = np.array([15, 255, 255])\n",
    "\n",
    "    lowerbound_2 = np.array([135, 40, 40])\n",
    "    upperbound_2 = np.array([180, 255, 255])\n",
    "\n",
    "    red_1 = cv.inRange(hsv_image, lowerbound_1, upperbound_1)\n",
    "    red_2 = cv.inRange(hsv_image, lowerbound_2, upperbound_2)\n",
    "    mask = cv.bitwise_or(red_1, red_2)\n",
    "\n",
    "\n",
    "    segmented_image = cv.bitwise_and(smooth_image, smooth_image, mask=mask)\n",
    "    BIN_THRESHOLD = 0.75\n",
    "\n",
    "    gray_image = weighted_gray_transform(segmented_image, [0, 0, 1])\n",
    "\n",
    "    threshold = int(255 * BIN_THRESHOLD)\n",
    "    ret_thresh, gray_image = cv.threshold(gray_image, threshold, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "red_segmented_image = segment_reds(src_image)\n",
    "fig, ax = display_gray_image(red_segmented_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blue Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_blues(bgr_image):\n",
    "    smooth_image = cv.edgePreservingFilter(bgr_image, flags=cv.NORMCONV_FILTER, sigma_s=50, sigma_r=0.5)\n",
    "    hsv_image = cv.cvtColor(smooth_image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Blue zones\n",
    "    lowerbound = np.array([100, 40, 70])\n",
    "    upperbound = np.array([140, 255, 255])\n",
    "\n",
    "    mask = cv.inRange(hsv_image, lowerbound, upperbound)\n",
    "    \n",
    "    segmented_image = cv.bitwise_and(smooth_image, smooth_image, mask=mask)\n",
    "    BIN_THRESHOLD = 0.25\n",
    "\n",
    "    # gray_image = cv.cvtColor(segmented_image, cv.COLOR_BGR2GRAY)\n",
    "    gray_image = weighted_gray_transform(segmented_image, [1, 0, 0])\n",
    "\n",
    "    threshold = int(255 * BIN_THRESHOLD)\n",
    "    ret_thresh, gray_image = cv.threshold(gray_image, threshold, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    # black_img = np.zeros(shape=bgr_image.shape[0:2], dtype=np.uint8)\n",
    "    # white_img = np.ones(shape=bgr_image.shape[0:2], dtype=np.uint8)*255\n",
    "    \n",
    "    # gray_image = cv.bitwise_or(black_img, white_img, mask=mask)\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "blue_segmented_image = segment_blues(processed_image)\n",
    "fig, ax = display_gray_image(blue_segmented_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(bgr_image):\n",
    "    B, G, R = cv.split(bgr_image)\n",
    "    hsv_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2HSV)    \n",
    "    _, S, _ = cv.split(hsv_image)\n",
    "\n",
    "    B, G, R = np.float64(B), np.float64(G), np.float64(R)\n",
    "    S = np.float64(S)\n",
    "\n",
    "    M, N, _ = bgr_image.shape\n",
    "    hd_blue = np.zeros(shape=(M, N), dtype=np.float64)\n",
    "    hd_red = np.zeros(shape=(M, N), dtype=np.float64)\n",
    "    sd = np.zeros(shape=(M, N), dtype=np.float64)\n",
    "    \n",
    "    RED_TH = 40\n",
    "    BLUE_TH = 40\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            b, g, r = B[i, j], G[i, j], R[i, j]\n",
    "            sat = S[i, j]\n",
    "            max_channel = np.argmax([b, g, r])\n",
    "            maxI = np.max([b, g, r])\n",
    "            minI = np.min([b, g, r])\n",
    "\n",
    "            if max_channel == 0: # B\n",
    "                hd_blue[i, j] = 1.0 - np.abs(r - g) / (maxI - minI + 1e-6) if (maxI - minI) > BLUE_TH else 0\n",
    "                hd_red[i, j] = 0\n",
    "            elif max_channel == 2: # R\n",
    "                hd_red[i, j] = 1.0 - np.abs(g - b) / (maxI - minI + 1e-6) if (maxI - minI) > RED_TH else 0\n",
    "                hd_blue[i, j] = 0\n",
    "            else:\n",
    "                hd_blue[i, j] = 0\n",
    "                hd_red[i, j] = 0\n",
    "            sd[i, j] = sat / 255.0\n",
    "\n",
    "    hs_red = np.uint8(hd_red * sd * 255)\n",
    "    hs_blue = np.uint8(hd_blue * sd * 255)\n",
    "\n",
    "    BIN_THRESHOLD = 0.5\n",
    "    threshold = int(255 * BIN_THRESHOLD)\n",
    "    ret_red_thresh, hs_red = cv.threshold(hs_red, threshold, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    ret_blue_thresh, hs_blue = cv.threshold(hs_blue, threshold, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "    return hs_red, hs_blue\n",
    "\n",
    "red_segmented_image, blue_segmented_image = segment(processed_image)\n",
    "display_gray_image(red_segmented_image)\n",
    "plt.clf();\n",
    "display_gray_image(blue_segmented_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Post-segmentation Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TODO: rethink the `removeSmallComponents`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# RoI Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this phase, it will be extracted the regions of interest (RoI) of the segmented images, those will be considered the potential traffic signs for the next phase. To do this extraction, it will be applied an edge detector followed by extracting the contours and then the bounding rectangle of that contour as the RoI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(gray_image):\n",
    "    # Apply morphological operation to soften possible artefacts\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, ksize=(3, 3))\n",
    "    morph_image = cv.morphologyEx(gray_image, cv.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    return cv.Canny(morph_image, threshold1=200, threshold2=240, apertureSize=5)\n",
    "\n",
    "    \n",
    "\n",
    "red_edges = edge_detection(red_segmented_image)\n",
    "print(\"Edges of Red Segmented Image\")\n",
    "fig, ax = display_gray_image(red_edges)\n",
    "plt.clf();\n",
    "\n",
    "blue_edges = edge_detection(blue_segmented_image)\n",
    "print(\"Edges of Blue Segmented Image\")\n",
    "fig, ax = display_gray_image(blue_edges)\n",
    "plt.clf();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract RoI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Regions of interest will be bounding rectangles of the contours detected in the image processed by Canny edge detector. To eliminate redundant RoI and false positives, RoI that are contained completely inside another will be merged, and RoI which don't meet certain criteria will also be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeROI(rois):\n",
    "    # Sort RoI by X-coordinate and width to merge RoI\n",
    "    sorted_rois = sorted(rois, key=lambda roi: (roi[0][0], -roi[0][2], roi[0][1], -roi[0][3]))\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= len(sorted_rois):\n",
    "            break\n",
    "\n",
    "        pivot = sorted_rois[i]\n",
    "        pivot_x0, pivot_y0, pivot_x1, pivot_y1 = pivot[0][0], pivot[0][1], pivot[0][0] + pivot[0][2], pivot[0][1] + pivot[0][3]\n",
    "        j = i + 1\n",
    "        while True:\n",
    "            if j >= len(sorted_rois):\n",
    "                break\n",
    "\n",
    "            other = sorted_rois[j]\n",
    "            other_x0, other_y0, other_x1, other_y1 = other[0][0], other[0][1], other[0][0] + other[0][2], other[0][1] + other[0][3]\n",
    "        \n",
    "            # Beginning of other RoI is already past the ending of the pivot RoI\n",
    "            if other_x0 > pivot_x1:\n",
    "                break\n",
    "\n",
    "            # Check if it's inside, and delete if so, otherwise advance\n",
    "            if other_y0 > pivot_y0 and other_y1 < pivot_y1 and other_x1 < pivot_x1:\n",
    "                sorted_rois.pop(j)\n",
    "            else:\n",
    "                j += 1\n",
    "        \n",
    "        i += 1\n",
    "    return sorted_rois\n",
    "\n",
    "\n",
    "def extractROI(edge_image, red_image, blue_image, roi_type):\n",
    "    kernel = cv.getStructuringElement(shape=cv.MORPH_ELLIPSE, ksize=(3, 3))\n",
    "    morph_image = cv.morphologyEx(edge_image, cv.MORPH_DILATE, kernel, iterations=1)\n",
    "\n",
    "    plt.clf()\n",
    "    contours, hierarchy = cv.findContours(morph_image, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Apply convex hulls to close off shapes\n",
    "    # contours = [cv.convexHull(contour) for contour in contours]\n",
    "\n",
    "    # Approximate contour\n",
    "    contours = [cv.approxPolyDP(contour, 0.004 * cv.arcLength(contour, True), True) for contour in contours]\n",
    "\n",
    "    rois = [(cv.boundingRect(contour), contour) for contour in contours]\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= len(rois):\n",
    "            break\n",
    "\n",
    "        (x, y, w, h), contours = rois[i]\n",
    "        roi_size = w * h\n",
    "\n",
    "        SIZE_THRESHOLD = 15 * 15\n",
    "        if roi_size < SIZE_THRESHOLD:\n",
    "            rois.pop(i)\n",
    "            continue\n",
    "\n",
    "        aspect_ratio = float(w) / (h + 1e-6)\n",
    "        if roi_type == \"red\":\n",
    "            ASPECT_RATIO_MIN = 0.45\n",
    "            ASPECT_RATIO_MAX = 1.55\n",
    "            if aspect_ratio < ASPECT_RATIO_MIN or aspect_ratio > ASPECT_RATIO_MAX: \n",
    "                rois.pop(i)\n",
    "                continue\n",
    "        elif roi_type == \"blue\":\n",
    "            ASPECT_RATIO_MIN = 0.45\n",
    "            ASPECT_RATIO_MAX = 2.0\n",
    "            if aspect_ratio < ASPECT_RATIO_MIN or aspect_ratio > ASPECT_RATIO_MAX: \n",
    "                rois.pop(i)\n",
    "                continue\n",
    "\n",
    "        blue_pixels = 0\n",
    "        red_pixels = 0\n",
    "        for xi in range(x, x+w):\n",
    "            for yi in range(y, y+h):\n",
    "                if cv.pointPolygonTest(contours, (xi, yi), measureDist=False) >= 0:\n",
    "                    if red_image[yi, xi] > 127:\n",
    "                        red_pixels += 1\n",
    "                    if blue_image[yi, xi] > 127:\n",
    "                        blue_pixels += 1\n",
    "\n",
    "        blue_ratio = blue_pixels / (roi_size + 1e-6)\n",
    "        red_ratio = red_pixels / (roi_size + 1e-6)\n",
    "        red_blue_ratio = red_pixels / (blue_pixels + 1e-6)\n",
    "\n",
    "        if roi_type == \"red\":\n",
    "            if red_ratio < 0.10:\n",
    "                rois.pop(i)\n",
    "                continue\n",
    "        elif roi_type == \"blue\":\n",
    "            if blue_ratio < 0.40:\n",
    "                rois.pop(i)\n",
    "                continue\n",
    "        \n",
    "        rois[i] = ((x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio)\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    rois = mergeROI(rois)\n",
    "    \n",
    "    return rois\n",
    "\n",
    "red_roi = extractROI(red_edges, red_image=red_segmented_image, blue_image=blue_segmented_image, roi_type=\"red\")\n",
    "\n",
    "blue_roi = extractROI(blue_edges, red_image=red_segmented_image, blue_image=blue_segmented_image, roi_type=\"blue\")\n",
    "\n",
    "roi_red_image = np.zeros(shape=(red_edges.shape + (3,)), dtype=np.uint8)\n",
    "brect_roi_red_image = cv.cvtColor(red_edges.copy(), cv.COLOR_GRAY2BGR)\n",
    "print(\"Red Regions of Interest\")\n",
    "for roi in red_roi:\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    cv.rectangle(brect_roi_red_image, (int(x), int(y)), (int(x+w), int(y+h)), (197, 183, 255), 1)\n",
    "\n",
    "    cv.rectangle(roi_red_image, (int(x), int(y)), (int(x+w), int(y+h)), (197, 183, 255), 1)\n",
    "    cv.drawContours(roi_red_image, [contours], 0, color=(255, 255, 255))\n",
    "    region = np.zeros_like(red_edges[y:y+h, x:x+w])\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "print(\"Edge image with bounding boxes and contours\")\n",
    "display_bgr_image(brect_roi_red_image)\n",
    "plt.clf();\n",
    "display_bgr_image(roi_red_image)\n",
    "plt.clf();\n",
    "\n",
    "print(\"Blue Regions of Interest\")\n",
    "roi_blue_image = np.zeros(shape=(blue_edges.shape + (3,)), dtype=np.uint8)\n",
    "brect_roi_blue_image = cv.cvtColor(blue_edges.copy(), cv.COLOR_GRAY2BGR)\n",
    "for roi in blue_roi:\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    cv.rectangle(brect_roi_blue_image, (int(x), int(y)), (int(x+w), int(y+h)), (197, 183, 255), 1)\n",
    "\n",
    "    cv.rectangle(roi_blue_image, (int(x), int(y)), (int(x+w), int(y+h)), (197, 183, 255), 1)\n",
    "    cv.drawContours(roi_blue_image, [contours], 0, color=(255, 255, 255))\n",
    "    region = np.zeros_like(blue_edges[y:y+h, x:x+w])\n",
    "    # for x0 in range(x, x+w):\n",
    "    #     for y0 in range(y, y+h):\n",
    "    #         if cv.pointPolygonTest(contours, (x0, y0), measureDist=False) >= 0:\n",
    "    #             region[y0-y, x0-x] = 255\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "print(\"Edge image with bounding boxes and contours\")\n",
    "display_bgr_image(brect_roi_blue_image)\n",
    "plt.clf();\n",
    "display_bgr_image(roi_blue_image)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Shape Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_detection(roi, gray_image):\n",
    "    (x, y, w, h), contours, _, _, _ = roi\n",
    "    region = np.zeros(shape=(h, w), dtype=np.uint8)\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "    region_32f = np.float32(region)\n",
    "\n",
    "    corners = cv.cornerHarris(region_32f, 6, 3, 0.04)\n",
    "    corners = cv.dilate(corners, None)\n",
    "\n",
    "    norm_corners = np.empty(corners.shape, dtype=np.float32)\n",
    "    cv.normalize(corners, norm_corners, 255.0, 0.0, cv.NORM_INF)\n",
    "    norm_corners = cv.convertScaleAbs(norm_corners)\n",
    "\n",
    "    CORNER_THRESHOLD = 60\n",
    "\n",
    "    ND = 7\n",
    "    P = 1.0 / ND\n",
    "    dw, dh = int(P * w), int(P * h)\n",
    "\n",
    "    tl = 0.25 * (norm_corners[0:, 0:dw].max() > CORNER_THRESHOLD)\n",
    "    tc = 0.25 * (norm_corners[0:dh, (ND // 2)*dw:(ND // 2 + 1)*dw].max() > CORNER_THRESHOLD)\n",
    "    tr = 0.25 * (norm_corners[0:dh, (ND - 1)*dw:ND*dw].max() > CORNER_THRESHOLD)\n",
    "\n",
    "    ml = 0.25 * (norm_corners[(ND // 2)*dh:(ND // 2 + 1)*dh, 0:dw].max() > CORNER_THRESHOLD)\n",
    "    mr = 0.25 * (norm_corners[(ND // 2)*dh:(ND // 2 + 1)*dh, (ND-1)*dw:ND*dw].max() > CORNER_THRESHOLD)\n",
    "\n",
    "    bl = 0.25 * (norm_corners[(ND-1)*dh:ND*dh, 0:dw].max() > CORNER_THRESHOLD)\n",
    "    bc = 0.25 * (norm_corners[(ND-1)*dh:ND*dh, (ND // 2)*dw:(ND // 2 + 1)*dw].max() > CORNER_THRESHOLD)\n",
    "    br = 0.25 * (norm_corners[(ND-1)*dh:ND*dh, (ND-1)*dw:ND*dw].max() > CORNER_THRESHOLD)\n",
    "\n",
    "    sqp = max([\n",
    "        clamp(tl + tr + br + bl - 0.5 * (ml + mr + tc + bc), 0.0, 1.0),\n",
    "        clamp(0.65 * (bl + br + tr + tc) - tl - 0.5 * ml - 0.8 * (bc + mr), 0.0, 1.0), # oriented rightwards up\n",
    "        clamp(0.65 * (bl + br + tl + tc) - tr - 0.5 * mr - 0.8 * (bc + ml), 0.0, 1.0), # oriented leftwards up\n",
    "        clamp(0.65 * (tl + tr + bl + bc) - br - 0.5 * mr - 0.8 * (tc + ml), 0.0, 1.0), # oriented rightwards down\n",
    "        clamp(0.65 * (tl + tr + br + bc) - bl - 0.5 * ml - 0.8 * (tc + mr), 0.0, 1.0), # oriented leftwards down\n",
    "    ])\n",
    "    tup = clamp(1/0.75 * (bl + br + tc) - 2.0 * (tl + tr) - 0.9 * (ml + mr), 0.0, 1.0)\n",
    "    tdp = clamp(1/0.75 * (tl + tr + bc) - 1.5 * (bl + br) - 0.9 * (ml + mr), 0.0, 1.0)\n",
    "    circle = clamp(tc + bc + ml + mr -0.25 * (tl + tr + bl + br), 0.0, 1.0)\n",
    "\n",
    "    display_gray_image(region)\n",
    "    plt.clf();\n",
    "    display_gray_image(norm_corners)\n",
    "    plt.clf();\n",
    "    return sqp, max(tup, tdp), circle\n",
    "\n",
    "print(\"Corner detection on reds\")\n",
    "for i in range(len(red_roi)):\n",
    "    roi = red_roi[i]\n",
    "    (brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    sqp, trg, circle = corner_detection(roi, red_edges)\n",
    "    red_roi[i] = ((brect_x, brect_y, brect_w, brect_h), contour,  red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle)\n",
    "\n",
    "print(\"Corner detection on blues\")\n",
    "for i in range(len(blue_roi)):\n",
    "    roi = blue_roi[i]\n",
    "    (brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio = roi\n",
    "    sqp, trg, circle = corner_detection(roi, blue_edges)\n",
    "    blue_roi[i] = ((brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometrical Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical ratios\n",
    "circularity_ratios = {\n",
    "    \"circle\": 1,\n",
    "    \"quadrilateral\": 0.70,\n",
    "    \"octagon\": 0.92,\n",
    "    \"triangle\": 0.41,\n",
    "    # \"diamond\": 0.64,\n",
    "}\n",
    "\n",
    "extent_ratios = {\n",
    "    \"circle\": 0.785,\n",
    "    \"quadrilateral\": 1,\n",
    "    \"octagon\": 0.829,\n",
    "    \"triangle\": 0.498,\n",
    "    # \"diamond\": 0.5,\n",
    "}\n",
    "\n",
    "minextent_ratios = {\n",
    "    \"circle\": 0.785,\n",
    "    \"quadrilateral\": 1,\n",
    "    \"octagon\": 0.829,\n",
    "    \"triangle\": 0.498,\n",
    "    # \"diamond\": 1\n",
    "}\n",
    "\n",
    "red_ratios = {\n",
    "    \"circle\": 0.30,\n",
    "    \"quadrilateral\": 0.0,\n",
    "    \"octagon\": 0.65,\n",
    "    \"triangle\": 0.20,\n",
    "}\n",
    "\n",
    "blue_ratios = {\n",
    "    \"circle\": 0.60,\n",
    "    \"quadrilateral\": 0.60,\n",
    "    \"octagon\": 0.0,\n",
    "    \"triangle\": 0.0,\n",
    "}\n",
    "\n",
    "output_classes = defaultdict(lambda: \"unknown\", {\n",
    "    (\"circle\", \"red\"): \"prohibitory\",\n",
    "    (\"triangle\", \"red\"): \"priority\",\n",
    "    (\"octagon\", \"red\"): \"stop\",\n",
    "\n",
    "    (\"quadrilateral\", \"blue\"): \"information\",\n",
    "    (\"circle\", \"blue\"): \"mandatory\",\n",
    "})\n",
    "\n",
    "def detect_shape(roi, roi_type, return_probabilities = False):\n",
    "    (brect_x, brect_y, brect_w, brect_h), contour, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle = roi\n",
    "\n",
    "    contourArea = cv.contourArea(contour)\n",
    "    contourPerimeter = cv.arcLength(contour, True)\n",
    "    # Bounding Rectangle Area - used to calculate extent of contour\n",
    "    brect_area = brect_w * brect_h\n",
    "    extent = contourArea / (brect_area + 1e-6)\n",
    "\n",
    "    # Minimum Bounding Rectangle - takes into account orientation and fits the bounding rectangle thighly\n",
    "    (min_brect_x0, min_brect_y0), (min_brect_x1, min_brect_y1), min_brect_angle = cv.minAreaRect(contour)\n",
    "    min_brect_area = abs(min_brect_x0 - min_brect_x1) * abs(min_brect_y0 - min_brect_y1)\n",
    "\n",
    "    min_extent = contourArea / (min_brect_area + 1e-6)\n",
    "\n",
    "    # Circularity - measures how compact the contour is\n",
    "    circularity = (4 * np.pi * contourArea) / (contourPerimeter * contourPerimeter + 1e-6)\n",
    "\n",
    "    # Minimum Enclosing Circle - similar to circularity\n",
    "    (min_circle_x, min_circle_y), circle_radius = cv.minEnclosingCircle(contour)\n",
    "    min_circle_area = np.pi * circle_radius * circle_radius\n",
    "\n",
    "    circle_extent = contourArea / (min_circle_area + 1e-6)\n",
    "\n",
    "    # if roi_type == \"red\":\n",
    "    #     corner_metrics = [sqp, trg, circle]\n",
    "    #     max_corner = np.argmax(corner_metrics)\n",
    "\n",
    "    #     if max_corner == 0: # Square\n",
    "\n",
    "    #         pass\n",
    "        \n",
    "    # if roi_type == \"blue\":\n",
    "    #     pass\n",
    "\n",
    "    metrics = [\"circularity\", \"circle_extent\", \"extent\", \"min_extent\"]\n",
    "    ratios = [circularity, circle_extent, extent, min_extent]\n",
    "    ratio_tables = [circularity_ratios, circularity_ratios, extent_ratios, minextent_ratios]\n",
    "    if roi_type == \"red\":\n",
    "        metrics.append(\"color_ratio\")\n",
    "        ratios.append(red_ratio)\n",
    "        ratio_tables.append(red_ratios)\n",
    "    elif roi_type == \"blue\":\n",
    "        metrics.append(\"color_ratio\")\n",
    "        ratios.append(blue_ratio)\n",
    "        ratio_tables.append(blue_ratios)\n",
    "    \n",
    "    metrics.append(\"corners\")\n",
    "    n_metrics = len(metrics)\n",
    "\n",
    "    classes = [\"circle\", \"quadrilateral\", \"octagon\", \"triangle\"] # Add diamond\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    probability_table = np.zeros(shape=(n_metrics + 1, n_classes + 1))\n",
    "    for i in range(n_metrics - 1):\n",
    "        ratio = ratios[i]\n",
    "        table = ratio_tables[i]\n",
    "        for j in range(n_classes):\n",
    "            shape_class = classes[j]\n",
    "            class_ratio = table[shape_class]\n",
    "            probability_table[i, j] = abs(ratio - class_ratio) # / (class_ratio + 1e-6)\n",
    "        \n",
    "        probability_table[i, n_classes] = np.sum(probability_table[i, 0:n_classes])\n",
    "        probability_table[i, 0:n_classes] = (1 - (probability_table[i, 0:n_classes] / (probability_table[i, n_classes] + 1e-6))) #/ (n_classes - 1)\n",
    "        probability_table[i, n_classes] = np.sum(probability_table[i, 0:n_classes])\n",
    "\n",
    "    # Add corners row\n",
    "    probability_table[n_metrics - 1, :n_classes] = np.array([circle, sqp, circle, trg])\n",
    "    # probability_table[n_metrics - 1, n_classes] = np.sum(probability_table[n_metrics - 1, 0:n_classes])\n",
    "    # probability_table[n_metrics - 1, :n_classes] /= (probability_table[n_metrics - 1, n_classes] + 1e-6)\n",
    "\n",
    "    probability_table[-1, :n_classes] = np.mean(probability_table[:-1, :-1], axis=0)\n",
    "    probability_table[-1, n_classes] = np.sum(probability_table[-1, 0:n_classes])\n",
    "\n",
    "    chosen_shape = \"\"\n",
    "    max_probability = -1\n",
    "    for i, shape in enumerate(classes):\n",
    "        p = probability_table[-1, i] \n",
    "        if p > max_probability:\n",
    "            chosen_shape = shape\n",
    "            max_probability = p\n",
    "\n",
    "    CONFIDENCE = 0.1 # Confidence threshold, how much % is needed to obtain majority\n",
    "    THRESHOLD = (1 / n_classes) * (1 + CONFIDENCE)\n",
    "    if max_probability < THRESHOLD:\n",
    "        chosen_shape = \"other\"\n",
    "        max_probability = -1\n",
    "\n",
    "    if roi_type == \"red\":\n",
    "        if chosen_shape == \"quadrilateral\":\n",
    "            chosen_shape = \"other\"\n",
    "        elif chosen_shape == \"circle\" or chosen_shape == \"octagon\":\n",
    "            if red_ratio > 0.45:\n",
    "                chosen_shape = \"octagon\"\n",
    "            else:\n",
    "                chosen_shape = \"circle\"\n",
    "    elif roi_type == \"blue\":\n",
    "        if chosen_shape == \"triangle\" or chosen_shape == \"octagon\":\n",
    "            chosen_shape = \"other\"\n",
    "\n",
    "    if return_probabilities:\n",
    "        df = pd.DataFrame(data=probability_table[:, :-1], columns=classes, index=metrics + [\"AVG(P)\"])\n",
    "        return chosen_shape, max_probability, df, THRESHOLD\n",
    "\n",
    "    return chosen_shape\n",
    "\n",
    "output_image = src_image.copy()\n",
    "print(\"Shape detection for red RoI\")\n",
    "for roi in red_roi:\n",
    "    shape, prob, prob_table, threshold = detect_shape(roi, \"red\", return_probabilities=True)\n",
    "\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle = roi\n",
    "    region = np.zeros_like(red_edges[y:y+h, x:x+w])\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "\n",
    "    print(f\"Red Ratio: {red_ratio}\")\n",
    "    print(f\"Blue Ratio: {blue_ratio}\")\n",
    "    print(f\"Red Blue Ratio: {red_blue_ratio}\")\n",
    "    print(f\"Number of sides (contours): {len(contours)}\")\n",
    "    print(f\"Detected {shape} with probability of {prob}. Minimum threshold was {threshold}\")\n",
    "    print(prob_table)\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "    # Draw output\n",
    "    if shape != \"other\":\n",
    "        cv.drawContours(output_image, [contours], 0, color=(25, 255, 40), thickness=2)\n",
    "        output_class = output_classes[(shape, \"red\")]\n",
    "        cv.putText(output_image, output_class, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.6, (25, 255, 40), 2, cv.LINE_AA)\n",
    "\n",
    "print(\"Shape detection for blue RoI\")\n",
    "for roi in blue_roi:\n",
    "    shape, prob, prob_table, threshold = detect_shape(roi, \"blue\", return_probabilities=True)\n",
    "\n",
    "    (x, y, w, h), contours, red_ratio, blue_ratio, red_blue_ratio, sqp, trg, circle = roi\n",
    "    region = np.zeros_like(blue_edges[y:y+h, x:x+w])\n",
    "    cv.drawContours(region, [contours], 0, color=(255), offset=(-x, -y))\n",
    "\n",
    "    print(f\"Red Ratio: {red_ratio}\")\n",
    "    print(f\"Blue Ratio: {blue_ratio}\")\n",
    "    print(f\"Red Blue Ratio: {red_blue_ratio}\")\n",
    "    print(f\"Number of sides (contours): {len(contours)}\")\n",
    "    print(f\"Detected {shape} with probability of {prob}. Minimum threshold was {threshold}\")\n",
    "    print(prob_table)\n",
    "    fig, ax = display_gray_image(region)\n",
    "    plt.clf();\n",
    "\n",
    "    # Draw output\n",
    "    if shape != \"other\":\n",
    "        cv.drawContours(output_image, [contours], 0, color=(25, 255, 40), thickness=2)\n",
    "        output_class = output_classes[(shape, \"blue\")]\n",
    "        cv.putText(output_image, output_class, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.6, (25, 255, 40), 2, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display_bgr_image(output_image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54c6638086fab4cdd44262421cfa14d1d96be689a356dd3ef0d28ae6e964d53f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
