{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Stage Object detection w/ Freeze Learning & Fine-tuning\n",
    "For this approach, it will be used a pretrained DensetNet201 as a backbone for a F-RCNN model for object detection, to which it will be applied freeze learning and fine-tuning to our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "IMG_DIR = DATA_DIR + \"/images/\"\n",
    "ANNOTATION_DIR = DATA_DIR + \"/annotations/\"\n",
    "SPLITS_DIR = DATA_DIR + \"/dl-split/\"\n",
    "OUT_DIR = \"./out/two_stage_obj_det/\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching pre-defined splits\n",
    "train_split = []\n",
    "test_split = []\n",
    "\n",
    "with open(SPLITS_DIR + \"/train.txt\") as train_split_f:\n",
    "    train_split = [line.strip(\"\\n\") for line in train_split_f.readlines()]\n",
    "\n",
    "with open(SPLITS_DIR + \"/test.txt\") as test_split_f:\n",
    "    test_split = [line.strip(\"\\n\") for line in test_split_f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "label_encode_map = {\n",
    "    \"background\": 0,\n",
    "    \"trafficlight\": 1,\n",
    "    \"speedlimit\": 2,\n",
    "    \"crosswalk\": 3,\n",
    "    \"stop\": 4,\n",
    "}\n",
    "\n",
    "label_decode_map = {\n",
    "    0: \"background\",\n",
    "    1: \"trafficlight\",\n",
    "    2: \"speedlimit\",\n",
    "    3: \"crosswalk\",\n",
    "    4: \"stop\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.road_sign_dataset import RoadSignDataset\n",
    "\n",
    "# Training dataset\n",
    "training_data = RoadSignDataset(\n",
    "    img_names=train_split,\n",
    "    img_dir=IMG_DIR,\n",
    "    annotation_dir=ANNOTATION_DIR,\n",
    "    classes=label_encode_map,\n",
    "    is_train=True,\n",
    "    multilabel=False,\n",
    "    obj_detection=True\n",
    ")\n",
    "\n",
    "# Test dataset\n",
    "testing_data = RoadSignDataset(\n",
    "    img_names=test_split,\n",
    "    img_dir=IMG_DIR,\n",
    "    annotation_dir=ANNOTATION_DIR,\n",
    "    classes=label_encode_map,\n",
    "    is_train=False,\n",
    "    multilabel=False,\n",
    "    obj_detection=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training dataset into train and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train_indices = list(range(len(training_data)))\n",
    "np.random.shuffle(train_indices)\n",
    "train_val_split = int(np.floor(0.2 * len(train_indices)))\n",
    "\n",
    "train_idx, val_idx = train_indices[train_val_split:], train_indices[:train_val_split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8 # Tested on 1050TI with 4GB\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=training_data,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False, # Must be False because we're using a random sampler already\n",
    "    drop_last=True,\n",
    "    collate_fn=training_data.collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=training_data,\n",
    "    sampler=val_sampler,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False, # Must be False because we're using a random sampler already\n",
    "    drop_last=True,\n",
    "    collate_fn=training_data.collate_fn\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=testing_data,\n",
    "    batch_size=1,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=testing_data.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "FasterRCNN                                    --\n",
       "├─GeneralizedRCNNTransform: 1-1               --\n",
       "├─BackboneWithFPN: 1-2                        --\n",
       "│    └─IntermediateLayerGetter: 2-1           --\n",
       "│    │    └─Conv2d: 3-1                       9,408\n",
       "│    │    └─BatchNorm2d: 3-2                  128\n",
       "│    │    └─ReLU: 3-3                         --\n",
       "│    │    └─MaxPool2d: 3-4                    --\n",
       "│    │    └─_DenseBlock: 3-5                  335,040\n",
       "│    │    └─_Transition: 3-6                  33,280\n",
       "│    │    └─_DenseBlock: 3-7                  919,680\n",
       "│    │    └─_Transition: 3-8                  132,096\n",
       "│    │    └─_DenseBlock: 3-9                  8,071,680\n",
       "│    │    └─_Transition: 3-10                 1,609,216\n",
       "│    │    └─_DenseBlock: 3-11                 6,978,560\n",
       "│    └─FeaturePyramidNetwork: 2-2             --\n",
       "│    │    └─ModuleList: 3-12                  1,147,904\n",
       "│    │    └─ModuleList: 3-13                  2,360,320\n",
       "│    │    └─LastLevelMaxPool: 3-14            --\n",
       "├─RegionProposalNetwork: 1-3                  --\n",
       "│    └─AnchorGenerator: 2-3                   --\n",
       "│    └─RPNHead: 2-4                           --\n",
       "│    │    └─Conv2d: 3-15                      590,080\n",
       "│    │    └─Conv2d: 3-16                      771\n",
       "│    │    └─Conv2d: 3-17                      3,084\n",
       "├─RoIHeads: 1-4                               --\n",
       "│    └─MultiScaleRoIAlign: 2-5                --\n",
       "│    └─TwoMLPHead: 2-6                        --\n",
       "│    │    └─Linear: 3-18                      12,846,080\n",
       "│    │    └─Linear: 3-19                      1,049,600\n",
       "│    └─FastRCNNPredictor: 2-7                 --\n",
       "│    │    └─Linear: 3-20                      5,125\n",
       "│    │    └─Linear: 3-21                      20,500\n",
       "======================================================================\n",
       "Total params: 36,112,552\n",
       "Trainable params: 36,112,552\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torchvision.models.detection.backbone_utils import (\n",
    "    LastLevelMaxPool,\n",
    "    BackboneWithFPN\n",
    ")\n",
    "from torchvision.ops import (\n",
    "    FeaturePyramidNetwork\n",
    ")\n",
    "from torchinfo import summary\n",
    "\n",
    "MODEL_NAME = \"FRCNN-Densenet201\"\n",
    "N_CLASSES = 4 + 1 # 4 target classes + background\n",
    "\"\"\"_summary_\n",
    "Adapted from fasterrcnn_resnet50_fpn at https://github.com/pytorch/vision/blob/c890a7e75ebeaaa75ae9ace4c203b7fc145df068/torchvision/models/detection/faster_rcnn.py\n",
    "\"\"\"\n",
    "def get_model(n_classes):\n",
    "    backbone = models.densenet169(pretrained=True)\n",
    "    \n",
    "    return_layers = [\"denseblock1\", \"denseblock2\", \"denseblock3\", \"denseblock4\"]\n",
    "    return_layers = {k: str(v) for v, k in enumerate(return_layers)}\n",
    "    in_channel_list = [256, 512, 1280, 1664]\n",
    "    backbone = BackboneWithFPN(\n",
    "        backbone=backbone.features,\n",
    "        return_layers=return_layers,\n",
    "        in_channels_list=in_channel_list,\n",
    "        out_channels=256,\n",
    "        extra_blocks=LastLevelMaxPool()\n",
    "    )\n",
    "    \n",
    "    model = models.detection.FasterRCNN(\n",
    "        backbone=backbone,\n",
    "        num_classes=n_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model(n_classes=N_CLASSES)\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Optimizer, LR Scheduler and Metric Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=5e-4,\n",
    "    amsgrad=True\n",
    ")\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=optimizer,\n",
    "    gamma=0.9\n",
    ")\n",
    "\n",
    "def get_metric_scorer():\n",
    "    # This needs to be instantied everytime, otherwise scores accumulate\n",
    "    return MeanAveragePrecision(box_format=\"xyxy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Epoch Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch_iter(dataloader, model, device, optimizer, lr_scheduler=None):\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for _batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "            for annotation in y:\n",
    "                annotation.pop(\"imageId\")\n",
    "                annotation.pop(\"areas\")\n",
    "            X = list(x.to(device) for x in X)\n",
    "            y = [ { k: v.to(device) for k, v in annotation.items() } for annotation in y]\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(X, y)\n",
    "\n",
    "            losses = sum(loss for loss in outputs.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(losses).backward()\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            total_loss += losses.item()\n",
    "\n",
    "            scaler.update()\n",
    "    \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch_iter(dataloader, model, device):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    expected_labels = []\n",
    "    imageIds = []\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for _batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "            X = list(x.to(device) for x in X)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(X)\n",
    "\n",
    "            for annotation in y:\n",
    "                imageIds.append(annotation.pop(\"imageId\").item())\n",
    "                annotation.pop(\"areas\")\n",
    "\n",
    "            # Put everything in CPU for safety\n",
    "            outputs = [ {k: v.detach().cpu() for k, v in o.items()} for o in outputs ]\n",
    "            y = [ {k: v.detach().cpu() for k, v in annotation.items()} for annotation in y]\n",
    "\n",
    "            preds.extend(outputs)\n",
    "            expected_labels.extend(y)\n",
    "            \n",
    "    return expected_labels, preds, imageIds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FRCNN-Densenet201 training...\n",
      "Epoch[1/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:29<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.010974\n",
      "----------------------------------------------------------------\n",
      "Epoch[2/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:18<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:42<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.066365\n",
      "----------------------------------------------------------------\n",
      "Epoch[3/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:13<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:38<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.096671\n",
      "----------------------------------------------------------------\n",
      "Epoch[4/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:11<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:37<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.112983\n",
      "----------------------------------------------------------------\n",
      "Epoch[5/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:12<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:39<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.149182\n",
      "----------------------------------------------------------------\n",
      "Epoch[6/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:17<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:44<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.133527\n",
      "----------------------------------------------------------------\n",
      "Epoch[7/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:13<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:43<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.151650\n",
      "----------------------------------------------------------------\n",
      "Epoch[8/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:13<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:37<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.147950\n",
      "----------------------------------------------------------------\n",
      "Epoch[9/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:10<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:43<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.238225\n",
      "----------------------------------------------------------------\n",
      "Epoch[10/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:08<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:44<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.184426\n",
      "----------------------------------------------------------------\n",
      "Epoch[11/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:07<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:38<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.194871\n",
      "----------------------------------------------------------------\n",
      "Epoch[12/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:12<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:39<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.198311\n",
      "----------------------------------------------------------------\n",
      "Epoch[13/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:10<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:36<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.191340\n",
      "----------------------------------------------------------------\n",
      "Epoch[14/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:08<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:39<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.246171\n",
      "----------------------------------------------------------------\n",
      "Epoch[15/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:12<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:43<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.203845\n",
      "----------------------------------------------------------------\n",
      "Epoch[16/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:07<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:37<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.161978\n",
      "----------------------------------------------------------------\n",
      "Epoch[17/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:09<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:37<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.228848\n",
      "----------------------------------------------------------------\n",
      "Epoch[18/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:09<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:36<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.256801\n",
      "----------------------------------------------------------------\n",
      "Epoch[19/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:08<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:37<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.265114\n",
      "----------------------------------------------------------------\n",
      "Epoch[20/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:07<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:36<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.226959\n",
      "----------------------------------------------------------------\n",
      "Epoch[21/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:10<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:41<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.221393\n",
      "----------------------------------------------------------------\n",
      "Epoch[22/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:07<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:39<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.291542\n",
      "----------------------------------------------------------------\n",
      "Epoch[23/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:12<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:39<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.262315\n",
      "----------------------------------------------------------------\n",
      "Epoch[24/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:12<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:42<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.287306\n",
      "----------------------------------------------------------------\n",
      "Epoch[25/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:07<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:41<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.249583\n",
      "----------------------------------------------------------------\n",
      "Epoch[26/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:11<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:40<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.279420\n",
      "----------------------------------------------------------------\n",
      "Epoch[27/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:10<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:38<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.328182\n",
      "----------------------------------------------------------------\n",
      "Epoch[28/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:08<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:39<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.258429\n",
      "----------------------------------------------------------------\n",
      "Epoch[29/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:06<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:43<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.306566\n",
      "----------------------------------------------------------------\n",
      "Epoch[30/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [04:07<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:42<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.294273\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Finished training...\n",
      "Best epoch: 1\t Validation mAP on best epoch: 0.010974389500916004\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "model.to(device)\n",
    "model.backbone.body.requires_grad_(False) # Freeze feature layer\n",
    "\n",
    "train_loss_history = []\n",
    "val_map_history = []\n",
    "\n",
    "best_map = np.inf\n",
    "best_epoch = -1\n",
    "\n",
    "print(f\"Starting {MODEL_NAME} training...\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"Epoch[{epoch}/{NUM_EPOCHS}]\")\n",
    "\n",
    "    train_loss = train_epoch_iter(\n",
    "        dataloader=train_dataloader,\n",
    "        model=model,\n",
    "        device=device,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler\n",
    "    )\n",
    "\n",
    "    print(f\"Training loss: {train_loss:.3f}\")\n",
    "\n",
    "    val_target, val_preds, _ = eval_epoch_iter(\n",
    "        dataloader=val_dataloader,\n",
    "        model=model,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    metric_scorer = get_metric_scorer()\n",
    "    \n",
    "    metric_scorer.update(val_preds, val_target)\n",
    "    # Only present mAP for simplicity\n",
    "    val_map = metric_scorer.compute()[\"map\"].item()\n",
    "    print(f\"Validation mAP: {val_map:3f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_map > best_map:\n",
    "        best_map = val_map\n",
    "        best_epoch = epoch\n",
    "        save_dict = {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict(), \"lr_scheduler\": lr_scheduler.state_dict(), \"epoch\": epoch}\n",
    "        torch.save(save_dict, f\"{OUT_DIR}/{MODEL_NAME}_best_model.pth\")\n",
    "\n",
    "    # Save latest model\n",
    "    save_dict = {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict(), \"lr_scheduler\": lr_scheduler.state_dict(), \"epoch\": epoch}\n",
    "    torch.save(save_dict, f\"{OUT_DIR}/{MODEL_NAME}_latest_model.pth\")\n",
    "\n",
    "    # Save loss and mAP in history\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    val_map_history.append(val_map)\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "print(\n",
    "    f\"\\nFinished training...\"\n",
    "    f\"\\nBest epoch: {best_epoch}\\t Validation mAP on best epoch: {best_map}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "706ee1819b983a943bbea807e6681581497887a5e921ebf85b777ef931d5d8ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
