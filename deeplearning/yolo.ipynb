{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Stage Object detection w/ Freeze Learning & Fine-tuning\n",
    "For this approach, it will be used a pretrained DensetNet201 as a backbone for a F-RCNN model for object detection, to which it will be applied freeze learning and fine-tuning to our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "IMG_DIR = DATA_DIR + \"/images/\"\n",
    "ANNOTATION_DIR = DATA_DIR + \"/annotations/\"\n",
    "SPLITS_DIR = DATA_DIR + \"/dl-split/\"\n",
    "OUT_DIR = \"./out/yolo_obj_detect/\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5 models/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train_names = []\n",
    "with open('../data/dl-split/train.txt', 'r') as train_f:\n",
    "    train_names = train_f.readlines()\n",
    "    train_names = [x.strip() for x in train_names]\n",
    "\n",
    "train_indices = list(range(len(train_names)))\n",
    "np.random.shuffle(train_indices)\n",
    "train_val_split = int(np.floor(0.2 * len(train_indices)))\n",
    "\n",
    "train_idx, val_idx = train_indices[train_val_split:], train_indices[:train_val_split]\n",
    "\n",
    "val_data = [train_names[idx] for idx in val_idx]\n",
    "train_data = [train_names[idx] for idx in train_idx]\n",
    "\n",
    "test_data = []\n",
    "with open('../data/dl-split/test.txt', 'r') as test_f:\n",
    "    test_data = test_f.readlines()\n",
    "    test_data = [x.strip() for x in train_names]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import parse_annotation\n",
    "import shutil\n",
    "\n",
    "TRAIN_DIR='../data/images/train'\n",
    "TEST_DIR='../data/images/test'\n",
    "VAL_DIR='../data/images/val'\n",
    "\n",
    "TRAIN_LABELS='../data/labels/train'\n",
    "TEST_LABELS='../data/labels/test'\n",
    "VAL_LABELS='../data/labels/val'\n",
    "\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_DIR, exist_ok=True)\n",
    "\n",
    "os.makedirs(TRAIN_LABELS, exist_ok=True)\n",
    "os.makedirs(TEST_LABELS, exist_ok=True)\n",
    "os.makedirs(VAL_LABELS, exist_ok=True)\n",
    "\n",
    "label_encode_map = {\n",
    "    \"trafficlight\": 0,\n",
    "    \"speedlimit\": 1,\n",
    "    \"crosswalk\": 2,\n",
    "    \"stop\": 3,\n",
    "}\n",
    "\n",
    "def transform_labels(out_path: str, annot_dict):\n",
    "    annot_file = open(out_path, 'w')\n",
    "    \n",
    "    img_width = annot_dict['width']\n",
    "    img_height = annot_dict['height']\n",
    "    for label, box in zip(annot_dict['labels'], annot_dict['boxes']):\n",
    "        width = (box[2]-box[0])/img_width\n",
    "        height = (box[3]-box[1])/img_height\n",
    "        \n",
    "        x_center = (box[0]+box[2])/2/img_width\n",
    "        y_center = (box[3]+box[1])/2/img_height\n",
    "        \n",
    "        annot_file.write(f'{label} {x_center} {y_center} {width} {height}\\n')\n",
    "    annot_file.close()\n",
    "\n",
    "# training data\n",
    "for name in train_data:\n",
    "    annot_dict = parse_annotation(f'../data/annotations/{name}.xml', label_encode_map)\n",
    "    transform_labels(f'{TRAIN_LABELS}/{name}.txt', annot_dict)\n",
    "    shutil.copy(src=f'../data/images/{name}.png', dst=TRAIN_DIR)\n",
    "  \n",
    "# validation data      \n",
    "for name in val_data:\n",
    "    annot_dict = parse_annotation(f'../data/annotations/{name}.xml', label_encode_map)\n",
    "    transform_labels(f'{VAL_LABELS}/{name}.txt', annot_dict)\n",
    "    shutil.copy(src=f'../data/images/{name}.png', dst=VAL_DIR)\n",
    " \n",
    "# test data       \n",
    "for name in test_data:\n",
    "    annot_dict = parse_annotation(f'../data/annotations/{name}.xml', label_encode_map)\n",
    "    transform_labels(f'{TEST_LABELS}/{name}.txt', annot_dict)\n",
    "    shutil.copy(src=f'../data/images/{name}.png', dst=TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python models/yolov5/train.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python models/yolov5/train.py --batch 4 --epochs 20 --data models/yolo_cfg.yaml --workers 2 --project out/yolo/ --optimizer SGD --hyp models/hyp.yaml"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
